{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "$ref": "#/definitions/pipeline",
  "additionalProperties": true,
  "definitions": {
    "output": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "path": {
          "description": "The path to a directory where the output will be taken from. If not\nspecified, the output's`name`is used.\n\nPaths are relative to the working directory of the task. Absolute paths are not respected.",
          "$ref": "#/definitions/dir_path"
        },
        "name": {
          "description": "The name of the output. The contents under`path`will be made\navailable to the rest of the plan under this name.",
          "$ref": "#/definitions/identifier"
        }
      }
    },
    "do_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "do": {
          "description": "@example Running multiple steps in a try\nThis can be used to perform multiple steps serially in a\n:\n\n```yaml\njobs:\n- name: with-do\n  plan:\n  - try:\n      do:\n      - get: black-ice\n      - get: control-node\n      - get: cyberdeck\n\nresources:\n- name: black-ice\n  type: mock\n- name: control-node\n  type: mock\n- name: cyberdeck\n  type: mock\n```",
          "type": "array",
          "items": {
            "description": "@example Running multiple steps in a try\nThis can be used to perform multiple steps serially in a\n:\n\n```yaml\njobs:\n- name: with-do\n  plan:\n  - try:\n      do:\n      - get: black-ice\n      - get: control-node\n      - get: cyberdeck\n\nresources:\n- name: black-ice\n  type: mock\n- name: control-node\n  type: mock\n- name: cyberdeck\n  type: mock\n```",
            "$ref": "#/definitions/step"
          }
        }
      }
    },
    "cache": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "path": {
          "description": "The path to a directory to be cached.\n\nPaths are relative to the working directory of the task. Absolute paths\nare not respected.",
          "$ref": "#/definitions/dir_path"
        }
      }
    },
    "env_vars": {
      "type": "string"
    },
    "version": {
      "type": "string"
    },
    "build_log_retention_policy": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "minimum_succeeded_builds": {
          "description": "Keep a minimum number of successful build logs that would normally be\nreaped.\n\nRequires\nto\nbe set to an integer higher than 0 in order to work. For example, if\nis\nset to 5, and this attribute to 1, say a job has the following build\nhistory: 7(f), 6(f), 5(f), 4(f), 3(f), 2(f), 1(s), where f means\nfailed and s means succeeded, then builds 2 and 3 will be reaped,\nbecause it retains 5 build logs, and at least 1 succeeded build log.\nDefault is 0.",
          "$ref": "#/definitions/number"
        },
        "builds": {
          "description": "Keep logs for the last specified number of builds.",
          "$ref": "#/definitions/number"
        },
        "days": {
          "description": "Keep logs for builds which have finished within the specified number of\ndays.",
          "$ref": "#/definitions/number"
        }
      }
    },
    "boolean": {
      "type": "boolean"
    },
    "number": {
      "type": "number"
    },
    "resource": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "source": {
          "description": "The configuration for the resource. This varies by resource type, and is a black\nbox to Concourse; it is blindly passed to the resource at runtime.\n\nTo use`git`as an example, the source may contain the repo URI, the\nbranch of the repo to track, and a private key to use when pushing/pulling.\n\nBy convention, documentation for each resource type's configuration is\nin each implementation's`README`.\n\nYou can find the source for the resource types provided with Concourse at the\n.",
          "$ref": "#/definitions/config"
        },
        "name": {
          "description": "The name of the resource. This should be short and simple. This name will\nbe referenced byof jobs in the\npipeline.",
          "$ref": "#/definitions/identifier"
        },
        "version": {
          "description": "A version to pin the resource to across the pipeline. This has the same\neffect as settingon every\nreferencing the resource.\n\nResources can also be temporarily pinned to a version via the API and web UI.\nHowever this functionality is disabled if the resource is pinned via\nconfiguration, and if a pipeline is configured to have a version pinned while\nalso pinned in the web UI, the configuration takes precedence and will clear\nout the temporary pin.",
          "$ref": "#/definitions/version"
        },
        "type": {
          "description": "Theimplementing the resource.",
          "$ref": "#/definitions/resource_type.name"
        },
        "check_every": {
          "description": "The interval on which to check for new versions\nof the resource. Acceptable interval options are defined by the\n.\n\nIf set to`never`the resource will not be automatically checked. The\nresource can still be checked manually via the web UI, fly, or webhooks.",
          "oneOf": [
            {
              "$ref": "#/definitions/duration"
            },
            {
              "type": "string",
              "enum": [
                "never"
              ]
            }
          ]
        },
        "expose_build_created_by": {
          "description": "If set to`true`, environment variable\nwill be available\nin the metadata of aor\n.",
          "$ref": "#/definitions/boolean"
        },
        "public": {
          "description": "If set to`true`, the metadata for each\nversion of the resource will be viewable by unauthenticated users (assuming\nthe pipeline has been).\n\nResource metadata should never contain credentials or secret information, but\nthis is off by default just to be safe in case users don't want to show\nthings like commit messages and authors to the public.\n\nNote: even when set to`false`, the versions identifiers will be\nvisible. In addition, if a resource is fetched in a build whose job is marked\n, metadata will be visible in the build output.",
          "$ref": "#/definitions/boolean"
        },
        "icon": {
          "description": "The name of a\nto show next to the resource name in the web UI. For example,\n`github`.",
          "$ref": "#/definitions/string"
        },
        "check_timeout": {
          "description": "The time limit on checking new versions of\nresources. Acceptable interval options are defined by the\n.",
          "$ref": "#/definitions/duration"
        },
        "tags": {
          "description": "A list of tags to determine which workers the\nchecks will be performed on. You'll want to specify this if the source is\ninternal to a worker's network, for example.\n\nThis does not apply tags to allor\nthat use the resource. If you want these steps\nto use tags, you must setfor each step.",
          "type": "array",
          "items": {
            "description": "A list of tags to determine which workers the\nchecks will be performed on. You'll want to specify this if the source is\ninternal to a worker's network, for example.\n\nThis does not apply tags to allor\nthat use the resource. If you want these steps\nto use tags, you must setfor each step.",
            "$ref": "#/definitions/string"
          }
        },
        "old_name": {
          "description": "The old name of the resource. If configured, the history of the old resource will be\ninherited to the new one. Once the pipeline is set, this field can be\nremoved as the history has been transferred.\n\n@example Renaming a resource\nThis can be used to rename a resource without losing its history, like so:\n\n```yaml\nresources:\n- name: new-name\n  old_name: current-name\n  type: git\n  source: {uri: \"https://github.com/vito/booklit\"}\n```\n\nAfter the pipeline is set, the resource was successfully renamed, so the `old_name` field can\nbe removed from the resource:\n\n```yaml\nresources:\n- name: new-name\n  type: git\n  source: {uri: \"https://github.com/vito/booklit\"}\n```",
          "$ref": "#/definitions/identifier"
        },
        "webhook_token": {
          "description": "If specified, web hooks can be sent to trigger an immediate\nof the resource, specifying this value as a primitive form of\nauthentication via query params.\n\nAfter configuring this value, you would then configure your hook sender with\nthe following painfully long path appended to your external URL:\n\n`\n      /api/v1/teams/TEAM_NAME/pipelines/PIPELINE_NAME/resources/RESOURCE_NAME/check/webhook?webhook_token=WEBHOOK_TOKEN\n    `\n\nForyou will\nneed to include the pipeline vars for a single pipeline instance. Currently\nyou can not have webhooks for all instances of a pipeline.\n\nThe pipeline vars should be added to the webhook URL as\nwith the format`vars.MY-VAR=\"SOME-VALUE\"`. A webhook URL for a\npipeline instance may look like this:\n\n`\n      /api/v1/teams/TEAM_NAME/pipelines/PIPELINE_NAME/resources/RESOURCE_NAME/check/webhook?webhook_token=WEBHOOK_TOKEN&vars.my-var=\"some-value\"&vars.second-var=\"two\"\n    `\n\nNote that the request payload sent to this API endpoint is entirely\nignored.  You should configure the resource as if you're not using web\nhooks, as the resourceis still\nthe \"source of truth.\"",
          "$ref": "#/definitions/string"
        }
      }
    },
    "input": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "path": {
          "description": "The path where the input will be placed. If not specified, the input's\n`name`is used.\n\nPaths are relative to the working directory of the task. Absolute paths\nare not respected.",
          "$ref": "#/definitions/dir_path"
        },
        "name": {
          "description": "The name of the input.",
          "$ref": "#/definitions/identifier"
        },
        "optional": {
          "description": "If`true`, then the input is not\nrequired by the task. The task may run even if this input is missing.\n\nAn`optional`input that is missing will not appear in the current\ndirectory of the running task.",
          "$ref": "#/definitions/boolean"
        }
      }
    },
    "command": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "args": {
          "description": "Arguments to pass to the command. Note that when executed with\n, any arguments passed to\nare appended to this array.",
          "type": "array",
          "items": {
            "description": "Arguments to pass to the command. Note that when executed with\n, any arguments passed to\nare appended to this array.",
            "$ref": "#/definitions/string"
          }
        },
        "path": {
          "description": "The name of or path to the executable to run.\n\n`path`is relative to the working directory. If`dir`is\nspecified to set the working directory, then`path`is relative to\nit.\n\nThis is commonly a path to a script provided by one of the task's inputs,\ne.g.`my-resource/scripts/test`. It could also be a command like\n`bash`(respecting standard`$PATH`lookup rules), or an absolute\npath to a file to execute, e.g.`/bin/bash`.",
          "$ref": "#/definitions/file_path"
        },
        "dir": {
          "description": "A directory, relative to the initial working directory, to set as the\nworking directory when running the script.",
          "$ref": "#/definitions/dir_path"
        },
        "user": {
          "description": "Explicitly set the user to run as. If not specified, this defaults to the\nuser configured by the task's image. If not specified there, it's up to\nthe Garden backend, and may be e.g.`root`on Linux.",
          "$ref": "#/definitions/string"
        }
      }
    },
    "task_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "image_resource": {
          "description": "The container image to run with, as provided by an anonymous\ndefinition.\n\nWhenever the task runs, the anonymous resource will be`check`ed to\ndiscover the latest version available. The image will then be fetched onto\nthe worker, if necessary, just prior to running the task.\n\nTo use an image provided by a previous step within your build plan, set\non the\ninstead.\n\n\n\n@example Using the`golang`Docker image\nThe following task config will use theto run`go version`:\n\n```yaml\nplatform: linux\n\nimage_resource:\n  type: registry-image\n  source: {repository: golang}\n\nrun:\n  path: go\n  args: [version]\n```",
          "$ref": "#/definitions/anonymous_resource"
        },
        "outputs": {
          "description": "The artifacts produced by the task.\n\nEach output configures a directory to make available to later steps in the\n. The directory will be automatically\ncreated before the task runs, and the task should place any artifacts it\nwants to export in the directory.",
          "type": "array",
          "items": {
            "description": "The artifacts produced by the task.\n\nEach output configures a directory to make available to later steps in the\n. The directory will be automatically\ncreated before the task runs, and the task should place any artifacts it\nwants to export in the directory.",
            "$ref": "#/definitions/output"
          }
        },
        "platform": {
          "description": "The platform the task should run on. This determines the pool of workers\nthat the task can run against.\n\nTechnically any string value is allowed so long as a worker advertises the\nsame platform, but in practice only`linux`,`darwin`, and\n`windows`are in use.",
          "type": "string",
          "enum": [
            "linux",
            "darwin",
            "windows"
          ]
        },
        "inputs": {
          "description": "The set of artifacts used by task, determining which artifacts will be\navailable in the current directory when the task runs.\n\nThese are satisfied bys or\nof a previous task. These can also\nbe provided by`-i`with.\n\nIf any required inputs are missing at run-time, then the task will error\nimmediately.",
          "type": "array",
          "items": {
            "description": "The set of artifacts used by task, determining which artifacts will be\navailable in the current directory when the task runs.\n\nThese are satisfied bys or\nof a previous task. These can also\nbe provided by`-i`with.\n\nIf any required inputs are missing at run-time, then the task will error\nimmediately.",
            "$ref": "#/definitions/input"
          }
        },
        "caches": {
          "description": "The cached directories shared between task runs.\n\nOn the task's first run, all cache directories will be empty. It is the\nresponsibility of the task to populate these directories with any artifacts\nto be cached. On subsequent runs, the cached directories will contain those\nartifacts.\n\nCaches are scoped to the worker the task is run on, so you will not get a\ncache hit when subsequent builds run on different workers. This also means\nthat caching is not intended to share state between workers, and your task\nshould be able to run whether or not the cache is warmed.\n\nCaches are also scoped to a particular task name inside of a pipeline's\njob. As a consequence, if the job name, step name or cache path are\nchanged, the cache will not be used. This also means that caches do not\nexist for one-off builds.",
          "type": "array",
          "items": {
            "description": "The cached directories shared between task runs.\n\nOn the task's first run, all cache directories will be empty. It is the\nresponsibility of the task to populate these directories with any artifacts\nto be cached. On subsequent runs, the cached directories will contain those\nartifacts.\n\nCaches are scoped to the worker the task is run on, so you will not get a\ncache hit when subsequent builds run on different workers. This also means\nthat caching is not intended to share state between workers, and your task\nshould be able to run whether or not the cache is warmed.\n\nCaches are also scoped to a particular task name inside of a pipeline's\njob. As a consequence, if the job name, step name or cache path are\nchanged, the cache will not be used. This also means that caches do not\nexist for one-off builds.",
            "$ref": "#/definitions/cache"
          }
        },
        "rootfs_uri": {
          "description": "A string specifying the rootfs uri of the container, as interpreted by your\nworker's Garden backend.\n\nis the preferred way to specify base image.\nYou should only use this if you have no other option and you really know\nwhat you're doing.",
          "$ref": "#/definitions/string"
        },
        "container_limits": {
          "description": "CPU and memory limits to enforce on the task container.\n\nNote that these values, when specified, will override any limits set by\npassing the`--default-task-cpu-limit`or\n`--default-task-memory-limit`flags to the`concourse web`command.",
          "$ref": "#/definitions/container_limits"
        },
        "run": {
          "description": "The command to execute in the container.\n\nNote that this isprovided as a script blob, but explicit\n`path`and`args`values; this allows`fly`to forward\narguments to the script, and forces your config`.yml`to stay fairly\nsmall.",
          "$ref": "#/definitions/command"
        },
        "params": {
          "description": "A key-value mapping of string keys and values that are exposed to the task\nvia environment variables.\n\nPipelines can override these params by setting\non the. This is a common\nmethod of providing credentials to a task.",
          "$ref": "#/definitions/env_vars"
        }
      }
    },
    "var_source": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "name": {
          "description": "The name of the`((var))`source. This should be short and\nsimple. This name will be referencedthroughout\nthe config.",
          "$ref": "#/definitions/string"
        }
      }
    },
    "display_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "background_image": {
          "description": "Allow users to specify a custom background image which is put at 30%\nopacity, grayscaled and blended into existing background. Must be an\nhttp, https, or relative URL.",
          "$ref": "#/definitions/string"
        }
      }
    },
    "set_pipeline_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "set_pipeline": {
          "description": "The identifier specifies the name of the pipeline to configure. Unless\nis set, it will be configured\nwithin the current team and be created. If set to`self`,\nthe current pipeline will update its own config.\n\n`set_pipeline: self`was introduced in Concourse v6.5.0. It is\nconsidered an**experimental**feature and may be removed at any\ntime. Contribute to the associated\n\nwith feedback.\n\n\n@example One pipeline configuring another\nThis is a way to ensure a pipeline stays up to date with its definition in\na source code repository, eliminating the need to manually run\n.\n\n```yaml\njobs:\n- name: set-pipeline\n  plan:\n  - get: examples\n    trigger: true\n  - set_pipeline: hello-world  # pipeline's name\n    file: examples/pipelines/hello-world.yml  # pipeline's config\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            },
            {
              "type": "string",
              "enum": [
                "self"
              ]
            }
          ]
        },
        "file": {
          "description": "The path to the pipeline's configuration file.\n\n`file`points at a`.yml`file containing the pipeline\nconfiguration, which allows this to be tracked with your resources or\ngenerated by a.\n\nThe first segment in the path should refer to another artifact from the\nplan, and the rest of the path is relative to that artifact.\n\n@example Fetching and configuring a pipeline\nThecan be used to fetch your configuration from\na`git`repo and auto-configure it using a\n:\n\n```yaml\njobs:\n- name: set-pipeline\n  plan:\n  - get: examples\n    trigger: true\n  - set_pipeline: hello-world  # pipeline's name\n    file: examples/pipelines/hello-world.yml  # pipeline's config\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/file_path"
        },
        "vars": {
          "description": "A map of template variables to pass to the pipeline config. Unlike\n,\n`vars`are solely used to for\n, and do not become a part of\nthe pipeline's identifier.\n\nNote that variables set with this field will not propagate to tasks configured\nvia. If you want those variables to be determined\nat the time the pipeline is set, useas well.\n\n@example Configuring static vars\n```yaml\njobs:\n- name: set-pipeline-vars-only\n  plan:\n  - get: examples\n  - set_pipeline: pipeline-set-with-vars\n    file: examples/pipelines/pipeline-vars.yml\n    vars:\n      first: initial\n      number: \"9000\"\n      hello: HAL\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/vars"
        },
        "var_files": {
          "description": "A list of paths to`.yml`files that will be passed to the\npipeline config in the same manner as the`--load-vars-from`flag\nto. This means that if a variable appears\nin multiple files, the value from a file that is passed later in the\nlist will override the values from files earlier in the list.\n\n@example Configuring static vars with a vars file\nWhere the vars file looks like:\n\n\nAnd the pipeline config is:\n\n```yaml\njobs:\n- name: set-pipeline-vars-only\n  plan:\n  - get: examples\n  - set_pipeline: pipeline-set-with-vars\n    file: examples/pipelines/pipeline-vars.yml\n    var_files:\n      - examples/pipelines/vars-file.yml\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "type": "array",
          "items": {
            "description": "A list of paths to`.yml`files that will be passed to the\npipeline config in the same manner as the`--load-vars-from`flag\nto. This means that if a variable appears\nin multiple files, the value from a file that is passed later in the\nlist will override the values from files earlier in the list.\n\n@example Configuring static vars with a vars file\nWhere the vars file looks like:\n\n\nAnd the pipeline config is:\n\n```yaml\njobs:\n- name: set-pipeline-vars-only\n  plan:\n  - get: examples\n  - set_pipeline: pipeline-set-with-vars\n    file: examples/pipelines/pipeline-vars.yml\n    var_files:\n      - examples/pipelines/vars-file.yml\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
            "$ref": "#/definitions/file_path"
          }
        },
        "team": {
          "description": "By default, the`set_pipeline`step sets the pipeline for the\nsamethat is running the build.\n\nThe`team`attribute can be used to specify another team.\n\nOnly theis allowed to set another team's\npipeline.  Any team other than theusing the\n`team`attribute will error, unless they reference their own team.\n\nThe`team`attribute was introduced in Concourse v6.4.0. It is\nconsidered an**experimental**feature and may be removed at any\ntime. Contribute to the associated\n\nwith feedback.\n\n@example Setting a pipeline on another team\n```yaml\njobs:\n- name: set-pipeline\n  plan:\n  - get: examples\n    trigger: true\n  - set_pipeline: hello-world\n    file: examples/pipelines/hello-world.yml\n    team: other-team  # name of the team goes here\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/identifier"
        },
        "instance_vars": {
          "description": "A map of instance vars used to identify\n. These vars will also be\n.\n\nNote that variables set with this field will not propagate to tasks configured\nvia. If you want those variables to be determined\nat the time the pipeline is set, useas well.\n\nare experimental\nand need to be enabled by setting the\n`--enable-pipeline-instances`flag on the.\n\n@example Configuring instance vars\nThe following pipeline will create one instance group with three\npipelines. The instance group is called`my-bots`and each\npipeline has a different set of`instance_vars`making it\ndistinct from the other pipelines in the instance group.\n```yaml\njobs:\n- name: set-pipeline-instance-group\n  plan:\n  - get: examples\n  - in_parallel:\n    - set_pipeline: my-bots\n      file: examples/pipelines/pipeline-vars.yml\n      instance_vars:\n        first: initial\n        number: \"9000\"\n        hello: HAL\n    - set_pipeline: my-bots\n      file: examples/pipelines/pipeline-vars.yml\n      instance_vars:\n        first: second\n        number: \"3000\"\n        hello: WALLY-E\n    - set_pipeline: my-bots\n      file: examples/pipelines/pipeline-vars.yml\n      instance_vars:\n        first: the-third\n        number: \"6000\"\n        hello: R2D2\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```\n@example Configuring instance vars and vars\nBoth`instance_vars`and`vars`may be statically. The\ndifference between the two fields is that`instance_vars`are\nused to identify a pipeline and render the pipeline config.\n`vars`are only used for rendering the pipeline config:\n\n```yaml\njobs:\n- name: set-pipeline-vars-and-instance-vars\n  plan:\n  - get: examples\n  - set_pipeline: my-bots\n    file: examples/pipelines/pipeline-vars.yml\n    instance_vars:\n      first: initial\n      number: \"9000\"\n    vars:\n      hello: HAL\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/vars"
        }
      }
    },
    "dummy_var_source": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "type": {
          "description": "The`dummy`type supports configuring a static map of vars to values.\n\nThis is really only useful if you have no better alternative for credential\nmanagement but still have sensitive values that you would like to\nthem from build output.",
          "type": "string",
          "enum": [
            "dummy"
          ]
        },
        "config": {
          "description": "",
          "$ref": "#/definitions/dummy_config"
        }
      }
    },
    "duration": {
      "type": "string"
    },
    "in_parallel_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "steps": {
          "description": "The steps to perform in parallel.\n@example Fetching artifacts in parallel\nUsing the`in_parallel`step where possible is the easiest way\nto speeding up a builds.\n\nIt is often used to fetch all dependent resources together at the\nstart of a build plan:\n\n```yaml\njobs:\n- name: get-in-parallel\n  plan:\n  - in_parallel:\n      limit: 2\n      fail_fast: false\n      steps:\n      - get: ci\n      - get: repo\n      - get: code\n\n\nresources:\n- name: repo\n  type: mock\n- name: code\n  type: mock\n- name: ci\n  type: mock\n```",
          "type": "array",
          "items": {
            "description": "The steps to perform in parallel.\n@example Fetching artifacts in parallel\nUsing the`in_parallel`step where possible is the easiest way\nto speeding up a builds.\n\nIt is often used to fetch all dependent resources together at the\nstart of a build plan:\n\n```yaml\njobs:\n- name: get-in-parallel\n  plan:\n  - in_parallel:\n      limit: 2\n      fail_fast: false\n      steps:\n      - get: ci\n      - get: repo\n      - get: code\n\n\nresources:\n- name: repo\n  type: mock\n- name: code\n  type: mock\n- name: ci\n  type: mock\n```",
            "$ref": "#/definitions/step"
          }
        },
        "fail_fast": {
          "description": "When enabled the parallel step will\nfail fast by returning as soon as any sub-step fails. This means that running steps\nwill be interrupted and pending steps will no longer be scheduled.",
          "$ref": "#/definitions/boolean"
        },
        "limit": {
          "description": "A sempahore which limits the\nparallelism when executing the steps in a`in_parallel`step.\nWhen set, the number of running steps will not exceed the limit.\n\nWhen not specified,`in_parallel`will execute all steps\nimmediately.\n@example Limiting parallelism\nUsing`limit`is useful for performing parallel execution of a\ngrowing number of tasks without overloading your workers. In the\nexample below, two tasks will be run in parallel and in order until\nall steps have been executed:\n\n```yaml\njobs:\n- name: limit-in-parallel\n  plan:\n  - get: examples\n  - in_parallel:\n      limit: 2\n      steps:\n      - task: print-date\n        file: examples/tasks/print-date.yml\n      - task: hello-world\n        file: examples/tasks/hello-world.yml\n      - task: print-var\n        file: examples/tasks/print-var.yml\n        vars:\n          my-var: hello\n          second-var: good-bye\n\n\nresources:\n- name: examples\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/number"
        }
      }
    },
    "in_parallel_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "in_parallel": {
          "description": "Steps are either configured as a array or within an\n.\n\n@example Fetching artifacts in parallel\nUsing the`in_parallel`step where possible is the easiest way\nto speeding up a builds.\n\nIt is often used to fetch all dependent resources together at the\nstart of a build plan:\n\n```yaml\njobs:\n- name: get-in-parallel\n  plan:\n  - in_parallel:\n    - get: ci\n    - get: repo\n    - get: code\n\n\nresources:\n- name: repo\n  type: mock\n- name: code\n  type: mock\n- name: ci\n  type: mock\n```\n\n@example Running a build matrix\nIf any step in the`in_parallel`fails, the build will fail, making it\nuseful for build matrices:\n\n```yaml\nplan:\n- get: some-repo\n- in_parallel:\n  - task: unit-windows\n    file: some-repo/ci/windows.yml\n  - task: unit-linux\n    file: some-repo/ci/linux.yml\n  - task: unit-darwin\n    file: some-repo/ci/darwin.yml\n```",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "$ref": "#/definitions/step"
              }
            },
            {
              "$ref": "#/definitions/in_parallel_config"
            }
          ]
        }
      }
    },
    "vault_var_source": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "type": {
          "description": "The`vault`type supports configuring a\nserver as a\n`((var))`source.",
          "type": "string",
          "enum": [
            "vault"
          ]
        },
        "config": {
          "description": "Configuration for the Vault server has the following schema:",
          "$ref": "#/definitions/vault_config"
        }
      }
    },
    "dummy_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "vars": {
          "description": "A mapping of var name to var value.",
          "$ref": "#/definitions/vars"
        }
      }
    },
    "group_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "name": {
          "description": "A unique name for the group. This should be short and simple as it will\nbe used as the tab name for navigation.",
          "$ref": "#/definitions/identifier"
        },
        "jobs": {
          "description": "A list of jobs that should appear in this group. A job may\nappear in multiple groups. Neighbours of jobs in the current group will also\nappear on the same page in order to give context of the location of the\ngroup in the pipeline.\n\nYou may also use any valid\nto represent several jobs, e.g.:\n\n```yaml\ngroups:\n- name: develop\n  jobs:\n  - terraform-*\n  - test\n  - deploy-{dev,staging}\n- name: ship\n  jobs:\n  - deploy-prod\n- name: all\n  jobs:\n  - \"*\"\n```\n\nIn this example, the`develop`group will match\n`terraform-apply`,`terraform-destroy`,`test`,\n`deploy-dev`,`deploy-staging`. The`ship`group will only match\n`deploy-prod`. The`all`group will match all jobs in the pipeline.\n\nNote that depending on how it's used,`*`,`{`, and\n`}`have special meaning in YAML, and may need to be quoted (as\nwas done in the`all`job above)",
          "type": "array",
          "items": {
            "description": "A list of jobs that should appear in this group. A job may\nappear in multiple groups. Neighbours of jobs in the current group will also\nappear on the same page in order to give context of the location of the\ngroup in the pipeline.\n\nYou may also use any valid\nto represent several jobs, e.g.:\n\n```yaml\ngroups:\n- name: develop\n  jobs:\n  - terraform-*\n  - test\n  - deploy-{dev,staging}\n- name: ship\n  jobs:\n  - deploy-prod\n- name: all\n  jobs:\n  - \"*\"\n```\n\nIn this example, the`develop`group will match\n`terraform-apply`,`terraform-destroy`,`test`,\n`deploy-dev`,`deploy-staging`. The`ship`group will only match\n`deploy-prod`. The`all`group will match all jobs in the pipeline.\n\nNote that depending on how it's used,`*`,`{`, and\n`}`have special meaning in YAML, and may need to be quoted (as\nwas done in the`all`job above)",
            "$ref": "#/definitions/job.name"
          }
        }
      }
    },
    "vars": {
      "type": "string"
    },
    "across_var": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "var": {
          "description": "The name of the variable that will be added to the\n. This variable will only be\naccessible in the scope of the step - each iteration of the step gets\nits own scope.\n\nIf a variable of the same name already exists in the parent scope, a\nwarning will be printed.",
          "$ref": "#/definitions/identifier"
        },
        "fail_fast": {
          "description": "When enabled, the`across`step will\nfail fast by returning as soon as any sub-step fails. This means that running steps\nwill be interrupted and pending steps will no longer be scheduled.",
          "$ref": "#/definitions/boolean"
        },
        "values": {
          "description": "The list of values that thewill\niterate over when running the substep. If multiple\nare configured, all combinations of values across all vars will run.\n\nThe list of values may also be interpolated. For instance, you may use\ntheto first load a list of\ninto a, and then iterate across that dynamic\nlist of values.\n\n@example Value combinations\nThe followingwill run the task\n`foo/build.yml`for each package defined in`foo/packages-to-build.json`\nwith Go 1.15 and 1.16.\n\n```yaml\nplan:\n- get: foo\n- load_var: packages\n  file: foo/packages-to-build.json\n- across:\n  - var: package\n    values: ((.:packages))\n  - var: go_version\n    values: ['1.15', '1.16']\n  task: build\n  file: foo/build.yml\n  vars:\n    go_version: ((.:go_version))\n    package: ((.:package))\n```\n\nSupposing`foo/packages-to-build.json`had the following content:\n```json\n[\"./cmd/first\", \"./cmd/second\", \"./cmd/third\"]\n```\n\n...then the task`foo/build.yml`would be run with the following\nvar combinations:",
          "type": "array",
          "items": {
            "description": "The list of values that thewill\niterate over when running the substep. If multiple\nare configured, all combinations of values across all vars will run.\n\nThe list of values may also be interpolated. For instance, you may use\ntheto first load a list of\ninto a, and then iterate across that dynamic\nlist of values.\n\n@example Value combinations\nThe followingwill run the task\n`foo/build.yml`for each package defined in`foo/packages-to-build.json`\nwith Go 1.15 and 1.16.\n\n```yaml\nplan:\n- get: foo\n- load_var: packages\n  file: foo/packages-to-build.json\n- across:\n  - var: package\n    values: ((.:packages))\n  - var: go_version\n    values: ['1.15', '1.16']\n  task: build\n  file: foo/build.yml\n  vars:\n    go_version: ((.:go_version))\n    package: ((.:package))\n```\n\nSupposing`foo/packages-to-build.json`had the following content:\n```json\n[\"./cmd/first\", \"./cmd/second\", \"./cmd/third\"]\n```\n\n...then the task`foo/build.yml`would be run with the following\nvar combinations:",
            "$ref": "#/definitions/value"
          }
        },
        "max_in_flight": {
          "description": "If set to`all`, the substep will run\nwith all combinations of the current var in parallel. If set to a\n, only that number of substeps may run in parallel.\n\n@example Multiple vars\nIf multipleare configured, the\neffective`max_in_flight`is multiplicative. For instance:\n\n```yaml\nplan:\n- across:\n  - var: var1\n    values: [a, b, c]\n    max_in_flight: all\n  - var: var2\n    values: [1, 2]\n  - var: var3\n    values: [foo, bar]\n    max_in_flight: 2\n```\n\nHere,**6 substeps**will run in parallel, since all 3 of\n`var1`'s values can run in parallel, and 2 of`var3`'s\nvalues can run in parallel.",
          "oneOf": [
            {
              "type": "string",
              "enum": [
                "all"
              ]
            },
            {
              "$ref": "#/definitions/number"
            }
          ]
        }
      }
    },
    "string": {
      "type": "string"
    },
    "step": {
      "type": "string"
    },
    "try_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "try": {
          "description": "Performs the given step, ignoring any failure and masking it with\nsuccess.\n\nThis can be used when you want to perform some side-effect, but you\ndon't really want the whole build to fail if it doesn't work.\n\n@example Allowing non-critical behavior to fail\nWhen emitting logs somewhere for analyzing later, if the destination flakes\nout it may not really be critical, so we may want to just swallow the\nerror:\n\n```yaml\nplan:\n- task: run-tests\n  config: # ...\n  on_success:\n    try:\n      put: test-logs\n      params:\n        from: run-tests/*.log\n- task: do-something-else\n  config: # ...\n```",
          "$ref": "#/definitions/step"
        }
      }
    },
    "value": {
      "type": "object",
      "patternProperties": {
        ".*": {
          "additionalProperties": true
        }
      }
    },
    "resource_type": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "defaults": {
          "description": "The default configuration for the resource type. This varies\nby resource type, and is a black box to Concourse; it is merged with\n(duplicate fields are overwritten by)\nand passed to the resource at runtime.\n\n@example Setting default configuration for resources\n```yaml\nresource_types:\n- name: gcs\n  type: registry-image\n  source:\n    repository: frodenas/gcs-resource\n  defaults:\n    json_key: ((default_key))\n\nresources:\n- name: bucket-a\n  type: gcs\n  source:\n    bucket: a\n\n- name: bucket-b\n  type: gcs\n  source:\n    bucket: b\n\n- name: bucket-c\n  type: gcs\n  source:\n    bucket: c\n    json_key: ((different_key))\n```\n\n@example Overriding default resource types\nSince it's possible to overwrite the base resource types, it can be\nused to give defaults to resources at the pipeline level.\n\n```yaml\nresource_types:\n- name: registry-image\n  type: registry-image\n  source:\n    repository: concourse/registry-image-resource\n  defaults:\n    registry_mirror:\n      host: https://registry.mirror.example.com\n\nresources:\n- name: mirrored-image\n  type: registry-image\n  source:\n    repository: busybox\n```\n\nAlternatively, the web node can be configured to use",
          "$ref": "#/definitions/config"
        },
        "check_every": {
          "description": "The interval on which to check for new versions\nof the resource type. Acceptable interval options are defined by the\n.",
          "$ref": "#/definitions/duration"
        },
        "name": {
          "description": "The name of the resource type. This should be short and simple. This name\nwill be referenced bydefined within\nthe same pipeline, ands used\nby tasks running in the pipeline.\n\nPipeline-provided resource types can override the core resource types by\nspecifying the same name.",
          "$ref": "#/definitions/identifier"
        },
        "params": {
          "description": "Arbitrary config to pass when running the`get`to fetch the resource\ntype's image.",
          "$ref": "#/definitions/config"
        },
        "source": {
          "description": "The configuration for the resource type's resource. This varies\nby resource type, and is a black box to Concourse; it is blindly passed to\nthe resource at runtime.\n\nTo use`registry-image`as an example, the source would contain something\nlike`repository: username/reponame`. See the(or whatever\nresource type your resource type uses) for more information.",
          "$ref": "#/definitions/config"
        },
        "type": {
          "description": "The type of the resource used to provide the resource type's container\nimage.\n\nThis is a bit meta. Usually this value will be`registry-image`as the\nresource type must result in a container image.\n\nA resource type's type can refer to other resource types, and can also use the\ncore type that it's overriding. This is useful for bringing in a newer or\nforked`registry-image`resource.",
          "oneOf": [
            {
              "$ref": "#/definitions/resource_type.name"
            },
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "tags": {
          "description": "A list of tags to determine which workers the\nchecks will be performed on. You'll want to specify this if the source is\ninternal to a worker's network, for example. See also\n.",
          "type": "array",
          "items": {
            "description": "A list of tags to determine which workers the\nchecks will be performed on. You'll want to specify this if the source is\ninternal to a worker's network, for example. See also\n.",
            "$ref": "#/definitions/string"
          }
        },
        "privileged": {
          "description": "If set to`true`, the resource's\ncontainers will be run with full capabilities, as determined by the worker\nbackend the task runs on.\n\nFor Linux-based backends it typically determines whether or not the\ncontainer will run in a separate user namespace, and whether the\n`root`user is \"actual\"`root`(if set to`true`) or a user\nnamespaced`root`(if set to`false`, the default).\n\nThis is a gaping security hole; only configure it if the resource type needs\nit (which should be called out in its documentation). This is not up to the\nresource type to decide dynamically, so as to prevent privilege escalation\nvia third-party resource type exploits.",
          "$ref": "#/definitions/boolean"
        }
      }
    },
    "job": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "on_error": {
          "description": "Step to execute when the job errors. Equivalent to the\nhook.",
          "$ref": "#/definitions/step"
        },
        "on_failure": {
          "description": "Step to execute when the job fails. Equivalent to the\nhook.",
          "$ref": "#/definitions/step"
        },
        "max_in_flight": {
          "description": "If set, specifies a maximum number of builds to run at a time. If\n`serial`or`serial_groups`are set, they take precedence and\nforce this value to be`1`.",
          "$ref": "#/definitions/number"
        },
        "serial": {
          "description": "If set to`true`, builds will queue up\nand execute one-by-one, rather than executing in parallel.",
          "$ref": "#/definitions/boolean"
        },
        "build_log_retention": {
          "description": "Configures the retention policy for build logs. This is useful if you have\na job that runs often but after some amount of time the logs aren't worth\nkeeping around.\n\nBuilds which are not retained by the configured policy will have their logs\nreaped. If this configuration is omitted, logs are kept forever (unless\nis configured globally).\n\n@example A complicated example\nThe following example will keep logs for any builds that have completed in\nthe last 2 days, while also keeping the last 1000 builds and at least 1\nsucceeded build.\n\n```yaml\njobs:\n- name: smoke-tests\n  build_log_retention:\n    days: 2\n    builds: 1000\n    minimum_succeeded_builds: 1\n  plan:\n  - get: 10m\n  - task: smoke-tests\n    # ...\n```\n\nIf more than 1000 builds finish in the past 2 days,of them\nwill be retained thanks to the\n\nconfiguration. Similarly, if there are 1000 builds spanning more than 2\ndays, they will also be kept thanks to the\n\nconfiguration. And if they all happened to have failed, the\n\nwill keep around at least one successful build. All policies operate\nindependently.",
          "$ref": "#/definitions/build_log_retention_policy"
        },
        "ensure": {
          "description": "Step to execute regardless of whether the job succeeds, fails, errors, or\naborts. Equivalent to thehook.",
          "$ref": "#/definitions/step"
        },
        "disable_manual_trigger": {
          "description": "If set to`true`, manual triggering of\nthe job (via the web UI or) will be disabled.",
          "$ref": "#/definitions/boolean"
        },
        "serial_groups": {
          "description": "When set to an array of arbitrary tag-like\nstrings, builds of this job and other jobs referencing the same tags will\nbe serialized.\n\n@example Limiting parallelism\nThis can be used to ensure that certain jobs do not run at the same time,\nlike so:\n\n```yaml\njobs:\n- name: job-a\n  serial_groups: [some-tag]\n- name: job-b\n  serial_groups: [some-tag, some-other-tag]\n- name: job-c\n  serial_groups: [some-other-tag]\n```\n\nIn this example,`job-a`and`job-c`can run concurrently, but\nneither job can run builds at the same time as`job-b`.\n\nThe builds are executed in their order of creation, across all jobs with\ncommon tags.",
          "type": "array",
          "items": {
            "description": "When set to an array of arbitrary tag-like\nstrings, builds of this job and other jobs referencing the same tags will\nbe serialized.\n\n@example Limiting parallelism\nThis can be used to ensure that certain jobs do not run at the same time,\nlike so:\n\n```yaml\njobs:\n- name: job-a\n  serial_groups: [some-tag]\n- name: job-b\n  serial_groups: [some-tag, some-other-tag]\n- name: job-c\n  serial_groups: [some-other-tag]\n```\n\nIn this example,`job-a`and`job-c`can run concurrently, but\nneither job can run builds at the same time as`job-b`.\n\nThe builds are executed in their order of creation, across all jobs with\ncommon tags.",
            "$ref": "#/definitions/identifier"
          }
        },
        "interruptible": {
          "description": "Normally, when a worker is shutting down it\nwill wait for builds with containers running on that worker to finish\nbefore exiting. If this value is set to`true`, the worker will not\nwait on the builds of this job. You may want this if e.g. you have a\nself-deploying Concourse or long-running-but-low-importance jobs.",
          "$ref": "#/definitions/boolean"
        },
        "plan": {
          "description": "The sequence ofto execute.",
          "type": "array",
          "items": {
            "description": "The sequence ofto execute.",
            "$ref": "#/definitions/step"
          }
        },
        "old_name": {
          "description": "The old name of the job. If configured, the history of old job will be\ninherited to the new one. Once the pipeline is set, this field can be\nremoved as the builds have been transfered.\n\n@example Renaming a job\nThis can be used to rename a job without losing its history, like so:\n\n```yaml\njobs:\n- name: new-name\n  old_name: current-name\n  plan: [{get: 10m}]\n```\n\nAfter the pipeline is set, because the builds have been inherited, the job can\nhave the field removed:\n\n```yaml\njobs:\n- name: new-name\n  plan: [{get: 10m}]\n```",
          "$ref": "#/definitions/identifier"
        },
        "build_logs_to_retain": {
          "description": "Equivalent to setting\n.",
          "$ref": "#/definitions/number"
        },
        "public": {
          "description": "If set to`true`, the build log of this\njob will be viewable by unauthenticated users. Unauthenticated users will\nalways be able to see the inputs, outputs, and build status history of a\njob. This is useful if you would like to expose your pipeline publicly\nwithout showing sensitive information in the build log.\n\nNote: when this is set to`true`, anyand\ns will show the metadata for their resource version,\nregardless of whether the resource itself has set\nto`true`.",
          "$ref": "#/definitions/boolean"
        },
        "on_success": {
          "description": "Step to execute when the job succeeds. Equivalent to the\nhook.",
          "$ref": "#/definitions/step"
        },
        "name": {
          "description": "The name of the job. This should be short; it will show up in URLs.",
          "$ref": "#/definitions/identifier"
        },
        "on_abort": {
          "description": "Step to execute when the job aborts. Equivalent to the\nhook.",
          "$ref": "#/definitions/step"
        }
      }
    },
    "container_limits": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "cpu": {
          "description": "The maximum amount of CPU available to the task container, measured in\nshares. 0 means unlimited.\n\nCPU shares are relative to the CPU shares of other containers on a\nworker. For example, if you have two containers both with a CPU\nlimit of 2 shares then each container will get 50% of the CPU's time.\n\n```\nContainer A: 2 shares - 50% CPU\nContainer B: 2 shares - 50% CPU\nTotal CPU shares declared: 4\n```\n\nIf you introduce another container then the number of CPU time per\ncontainer changes. CPU shares are relative to each other.\n```\nContainer A: 2 shares - 25% CPU\nContainer B: 2 shares - 25% CPU\nContainer C: 4 shares - 50% CPU\nTotal CPU shares declared: 8\n```",
          "$ref": "#/definitions/number"
        },
        "memory": {
          "description": "The maximum amount of memory available to the task container, measured in\nbytes. 0 means unlimited.",
          "$ref": "#/definitions/number"
        }
      }
    },
    "pipeline": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "display": {
          "description": "`display`was introduced in Concourse v6.6.0. It is considered an\n**experimental**feature.\n\nVisual configurations for personalizing your pipeline.\n\n@example Background image\nThe following example will display an image in the background of the pipeline\nit is configured on.\n\n```yaml\ndisplay:\n  background_image: https://avatars1.githubusercontent.com/u/7809479?s=400&v=4\n```",
          "$ref": "#/definitions/display_config"
        },
        "var_sources": {
          "description": "A set offor the pipeline to use.",
          "type": "array",
          "items": {
            "description": "A set offor the pipeline to use.",
            "$ref": "#/definitions/var_source"
          }
        },
        "groups": {
          "description": "A list of job groups to use for organizing jobs in the web UI.\n\nGroups have no functional effect on your pipeline. They are purely for\nmaking it easier to grok large pipelines in the web UI.\n\nNote: once you have added groups to your pipeline, all jobs must be in a\ngroup.\n\n@example Grouping jobs\nThe following example will make the \"tests\" group the default view (since\nit's listed first), separating the later jobs into a \"publish\" group:\n\n```yaml\ngroups:\n- name: test\n  jobs:\n  - unit\n  - integration\n- name: publish\n  jobs:\n  - deploy\n  - shipit\n```\n\nThis would display two tabs at the top of the home page: \"test\" and\n\"publish\".\n\nFor a real world example of how groups can be used to simplify navigation\nand provide logical grouping, see the groups used at the top of the page\nin the.",
          "type": "array",
          "items": {
            "description": "A list of job groups to use for organizing jobs in the web UI.\n\nGroups have no functional effect on your pipeline. They are purely for\nmaking it easier to grok large pipelines in the web UI.\n\nNote: once you have added groups to your pipeline, all jobs must be in a\ngroup.\n\n@example Grouping jobs\nThe following example will make the \"tests\" group the default view (since\nit's listed first), separating the later jobs into a \"publish\" group:\n\n```yaml\ngroups:\n- name: test\n  jobs:\n  - unit\n  - integration\n- name: publish\n  jobs:\n  - deploy\n  - shipit\n```\n\nThis would display two tabs at the top of the home page: \"test\" and\n\"publish\".\n\nFor a real world example of how groups can be used to simplify navigation\nand provide logical grouping, see the groups used at the top of the page\nin the.",
            "$ref": "#/definitions/group_config"
          }
        },
        "resources": {
          "description": "A set offor the pipeline to continuously\ncheck.",
          "type": "array",
          "items": {
            "description": "A set offor the pipeline to continuously\ncheck.",
            "$ref": "#/definitions/resource"
          }
        },
        "resource_types": {
          "description": "A set offor resources within the\npipeline to use.",
          "type": "array",
          "items": {
            "description": "A set offor resources within the\npipeline to use.",
            "$ref": "#/definitions/resource_type"
          }
        },
        "jobs": {
          "description": "A set offor the pipeline to continuously schedule. At least one job is required for a pipeline to be valid.",
          "type": "array",
          "items": {
            "description": "A set offor the pipeline to continuously schedule. At least one job is required for a pipeline to be valid.",
            "$ref": "#/definitions/job"
          }
        }
      }
    },
    "file_path": {
      "type": "string"
    },
    "get_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "get": {
          "description": "The fetched bits will be registered in the build's artifact namespace\nunder the given identifier. Subsequentand\nwhich list the identifier as an input will have a\ncopy of the bits in their working directory.\n\n@example Fetching a repo and passing it to a task\nAlmost every simple job will look something like this: fetch my code\nwith aand do something (run tests) with it in a\n.\n\n```yaml\njobs:\n- name: fetch-repo\n  plan:\n  - get: repo # fetches repo under artifact name \"repo\"\n  - task: ls-repo\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      # pass the \"repo\" artifact into the task\n      inputs:\n      - name: repo\n      run:\n        path: ls\n        args: [\"-lah\",\"repo\"]\n\nresources:\n- name: repo\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/resource.name"
            },
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "passed": {
          "description": "When specified, only the versions of the resource that made it through\nthe given list of jobs (AND-ed together) will be considered when\ntriggering and fetching.\n\n@example Fanning out and in\nIf multiple`get`s are configured with`passed`\nconstraints, all of the mentioned jobs are correlated.\n\n```yaml\njobs:\n- name: lvl-1-firewall\n  plan:\n  - in_parallel:\n    - get: black-ice\n    - get: control-node\n    - get: cyberdeck\n\n- name: lvl-2-unit\n  plan:\n  - in_parallel:\n    - get: black-ice\n      passed: [lvl-1-firewall]\n    - get: control-node\n      passed: [lvl-1-firewall]\n    - get: cyberdeck\n      passed: [lvl-1-firewall]\n\n- name: lvl-2-integration\n  plan:\n  - in_parallel:\n    - get: black-ice\n      passed: [lvl-1-firewall]\n    - get: control-node\n      passed: [lvl-1-firewall]\n    - get: cyberdeck\n      passed: [lvl-1-firewall]\n\n- name: lvl-3-production\n  plan:\n  - in_parallel:\n    - get: black-ice\n      passed: [lvl-2-unit,lvl-2-integration]\n    - get: control-node\n      passed: [lvl-2-unit,lvl-2-integration]\n    - get: cyberdeck\n      passed: [lvl-2-unit,lvl-2-integration]\n\nresources:\n- name: black-ice\n  type: mock\n  source:\n    initial_version: lvl4\n- name: control-node\n  type: mock\n  source:\n    initial_version: tower\n- name: cyberdeck\n  type: mock\n  source:\n    initial_version: mk3\n```\n\nFor the final job,`lvl-3-production`, only versions that have\npassed the previous two jobs (`lvl-2-unit`and\n`lvl-2-integration`) will be passed to`lvl-3-production`.\n\nThis is crucial to being able to implement safe \"fan-in\" semantics as\nthings progress through a pipeline.",
          "type": "array",
          "items": {
            "description": "When specified, only the versions of the resource that made it through\nthe given list of jobs (AND-ed together) will be considered when\ntriggering and fetching.\n\n@example Fanning out and in\nIf multiple`get`s are configured with`passed`\nconstraints, all of the mentioned jobs are correlated.\n\n```yaml\njobs:\n- name: lvl-1-firewall\n  plan:\n  - in_parallel:\n    - get: black-ice\n    - get: control-node\n    - get: cyberdeck\n\n- name: lvl-2-unit\n  plan:\n  - in_parallel:\n    - get: black-ice\n      passed: [lvl-1-firewall]\n    - get: control-node\n      passed: [lvl-1-firewall]\n    - get: cyberdeck\n      passed: [lvl-1-firewall]\n\n- name: lvl-2-integration\n  plan:\n  - in_parallel:\n    - get: black-ice\n      passed: [lvl-1-firewall]\n    - get: control-node\n      passed: [lvl-1-firewall]\n    - get: cyberdeck\n      passed: [lvl-1-firewall]\n\n- name: lvl-3-production\n  plan:\n  - in_parallel:\n    - get: black-ice\n      passed: [lvl-2-unit,lvl-2-integration]\n    - get: control-node\n      passed: [lvl-2-unit,lvl-2-integration]\n    - get: cyberdeck\n      passed: [lvl-2-unit,lvl-2-integration]\n\nresources:\n- name: black-ice\n  type: mock\n  source:\n    initial_version: lvl4\n- name: control-node\n  type: mock\n  source:\n    initial_version: tower\n- name: cyberdeck\n  type: mock\n  source:\n    initial_version: mk3\n```\n\nFor the final job,`lvl-3-production`, only versions that have\npassed the previous two jobs (`lvl-2-unit`and\n`lvl-2-integration`) will be passed to`lvl-3-production`.\n\nThis is crucial to being able to implement safe \"fan-in\" semantics as\nthings progress through a pipeline.",
            "$ref": "#/definitions/job.name"
          }
        },
        "version": {
          "description": "The version of the resource to fetch.\n\nIf set to`latest`, scheduling will just find the latest available\nversion of a resource and use it, allowing versions to be skipped.  This is\nusually what you want, e.g. if someone pushes 100 git commits.\n\nIf set to`every`, builds will walk through all available versions of\nthe resource. Note that if`passed`is also configured, it will only\nstep through the versions satisfying the constraints.\n\nIf set to a specific version (e.g.`{ref: abcdef123}`), only that\nversion will be used. Note that the version must be available and detected by\nthe resource, otherwise the input will never be satisfied. You may want to\nuseto force detection of resource versions,\nif you need to use an older one that was never detected (as all newly\nconfigured resources start from the latest version).",
          "oneOf": [
            {
              "type": "string",
              "enum": [
                "latest"
              ]
            },
            {
              "type": "string",
              "enum": [
                "every"
              ]
            },
            {
              "$ref": "#/definitions/version"
            }
          ]
        },
        "params": {
          "description": "Arbitrary configuration to pass to the resource. Refer to the resource\ntype's documentation to see what it supports.\n\n@example Fetching with`params`\n```yaml\njobs:\n- name: resource-params\n  plan:\n  - get: cyberdeck\n    params:\n      create_files_via_params:\n        version_to_put.txt: \"made-via-params\"\n  - put: cyberdeck\n    params:\n      file: cyberdeck/version_to_put.txt\n\n\nresources:\n- name: cyberdeck\n  type: mock\n```",
          "$ref": "#/definitions/config"
        },
        "resource": {
          "description": "The resource to fetch,\nas configured in.\n\nUse this attribute to rename a resource from the overall pipeline context\ninto the job-specific context.\n\n@example Re-labelling artifact\n```yaml\njobs:\n- name: fetch-repo\n  plan:\n  - get: thecode # fetches \"repo\" under artifact name \"thecode\"\n    resource: repo\n  - task: ls-repo\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      # pass the \"thecode\" artifact into the task\n      inputs:\n      - name: thecode\n      run:\n        path: ls\n        args: [\"-lah\",\"thecode\"]\n\nresources:\n- name: repo\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/resource.name"
        },
        "trigger": {
          "description": "If set to`true`, new builds of the\njob will be automatically created when a new version for this input\nbecomes available.\n\nNote: if none of a job's`get`steps are set to`true`, the\njob can only be manually triggered.\n\n@example Automatically trigger job on new versions\n```yaml\njobs:\n- name: fetch-repo\n  plan:\n  - get: repo\n    trigger: true # automatically runs the job\n  - task: ls-repo\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      inputs:\n      - name: repo\n      run:\n        path: ls\n        args: [\"-lah\",\"repo\"]\n\nresources:\n- name: repo\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/boolean"
        }
      }
    },
    "task_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "file": {
          "description": "A dynamic alternative to.\n\n`file`points at a`.yml`file containing the\n, which allows this to be tracked with\nyour resources.\n\nThe first segment in the path should refer to another source from the\nplan, and the rest of the path is relative to that source.\n\nThe content of the config file may contain template`((vars))`,\nwhich will be filled in using\nor a configured.\n@example Using a task config file\nUses.\n```yaml\njobs:\n- name: task-config-in-file\n  plan:\n  - get: ci\n  - task: config-from-file\n    file: ci/tasks/hello-world.yml\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/file_path"
        },
        "container_limits": {
          "description": "CPU and memory limits to enforce on the task container.\n\nNote that these values, when specified, will override any limits set by\npassing the`--default-task-cpu-limit`or\n`--default-task-memory-limit`flags to the`concourse web`command.\n\nThese values will also override any configuration set on a\n.\n\n\n\n\n\n@example Setting CPU and Memory limits\nThis task will only be given 10MB of memory and 2 CPU shares.\n\n```yaml\njobs:\n- name: limited-resources\n  plan:\n  - task: constrained-task\n    container_limits:\n      cpu: 2 # CPU shares are relative\n      memory: 10000000 # 10MB\n    config:\n      platform: linux\n      image_resource:\n        type: registry-image\n        source: { repository: busybox }\n      run:\n        path: echo\n        args: [\"Hello world!\"]\n```",
          "$ref": "#/definitions/container_limits"
        },
        "params": {
          "description": "A map of task environment variable parameters to set, overriding those\nconfigured in the task's`config`or`file`.\n\nThe difference between\nandis that\nallows you to interpolate any\ntemplate variable in an external task file, while\ncan be used to overwrite\ntask parameters specifically. Also,\ncan have default values\ndeclared in the task.\n\n@example Running a task with env var params\nLet's say we have alike\nso:\n\n\n\nThis indicates that there are two params which can be set:\n`ECHO_ME`, which has a default, and`ALSO_ME`which has no\ndefault set.\n\nA pipeline could run the task with values passed in like so:\n\n```yaml\njobs:\n- name: task-params\n  plan:\n  - get: ci\n  - task: constrained-task\n    file: ci/tasks/print-param.yml\n    params:\n      ECHO_ME: \"Eat your fruits\"\n      ALSO_ME: \"veggies\"\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```\n\n@example Using with`((vars))`\n```yaml\njobs:\n- name: task-params\n  plan:\n  - get: ci\n  - task: constrained-task\n    file: ci/tasks/print-param.yml\n    params:\n      ECHO_ME: ((some-var))\n      ALSO_ME: ((another-var))\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/env_vars"
        },
        "output_mapping": {
          "description": "A map from task output names to concrete names to register in the build\nplan. This allows a task with generic output names to be used multiple\ntimes in the same plan.\n\n@example Using with`input_mapping`\nThis is often used together with\n:\n\nGiven this task config:\n\n\nThis pipeline will map the inputs and outputs of the task to match\nthe name of the resources in the pipeline.\n```yaml\njobs:\n- name: task-output-mapping\n  plan:\n  - in_parallel:\n    - get: repo\n    - get: repo-dev\n    - get: ci\n  - task: create-outputs\n    input_mapping:\n      main: repo\n      dev: repo-dev\n    output_mapping:\n      main: repo\n      dev: repo-dev\n    file: ci/tasks/generic-outputs.yml\n  - in_parallel:\n    - put: repo\n      params:\n        file: repo/version\n    - put: repo-dev\n      params:\n        file: repo-dev/version\n\nresources:\n- name: repo\n  type: mock\n- name: repo-dev\n  type: mock\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/\\{output.name: identifier\\}"
        },
        "privileged": {
          "description": "If set to`true`, the task will run\nwith escalated capabilities available on the task's platform.\n\nSetting`privileged: true`is a gaping security hole; use wisely\nand only if necessary. This is not part of the task configuration in\norder to prevent privilege escalation via pull requests changing the\ntask file.\n\nFor the`linux`platform, this determines whether or not the\ncontainer will run in a separate user namespace. When set to\n`true`, the container's`root`user is\n`root`, i.e. not in a user namespace. This is not recommended, and\nshouldbe used with code you do not trust - e.g. pull\nrequests.\n\nFor macOS and Windows this field has no effect since workloads on\nthose machines are not containerized.",
          "$ref": "#/definitions/boolean"
        },
        "image": {
          "description": "Specifies an artifact source containing an image to use for the task.\nThis overrides anyconfiguration present in\nthe task configuration.\n\nThis is very useful when part of your pipeline involves building an image,\npossibly with dependencies pre-baked. You can then propagate that image\nthrough the rest of your pipeline, guaranteeing that the correct version (and\nthus a consistent set of dependencies) is used throughout your pipeline.\n\n@example Fetching and using an image\nThis can be used to explicitly keep track of dependent images. You\ncould also modify it to build and push the image in one job and use\nit in later jobs. See.\n\n```yaml\nresources:\n- name: golang\n  type: registry-image\n  source:\n    repository: golang  # could also be the full URL \"docker.io/golang\"\n    tag: \"1.17\"\n\njobs:\n- name: fetch-and-run-image\n  plan:\n  - get: golang\n  - task: use-fetched-image-in-task\n    image: golang   # reference the image from the get step\n    config:\n      platform: linux\n      run:\n        path: go\n        args: [\"version\"]\n```\n\n@example Building and using an image",
          "$ref": "#/definitions/identifier"
        },
        "task": {
          "description": "The identifier value is just a name - short and sweet. The value is\nshown in the web UI but otherwise has no affect on anything. This may\nchange in the future;proposes that the name\nbe used to reference a file within the project.\n\n@example Functions from inputs to outputs\nYou can think of tasks like functions. They have predefined inputs\nand outputs and can be written in idempotent ways.\n\nThe following pipeline contains a function that increments a number.\nYou can think of the task`add-one`like this pseudo-function:\n\n```\nfunc AddOne(num int) int {\n  return num + 1\n}\n```\n\n```yaml\njobs:\n- name: idempotent-task\n  plan:\n  - get: counter\n  - task: add-one\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      inputs:\n      - name: counter\n      outputs:\n      - name: counter\n      run:\n        path: sh\n        args:\n        - -c\n        - |\n          COUNTER=$(cat counter/version)\n          NEXT=$(($COUNTER + 1))\n          echo \"new version: $NEXT\"\n          echo $NEXT > counter/next\n  - put: counter\n    params:\n      file: counter/next\n\nresources:\n- name: counter\n  type: mock\n  source:\n    initial_version: \"1\"\n```",
          "$ref": "#/definitions/identifier"
        },
        "vars": {
          "description": "A map of template variables to pass to an external task. Not to be\nconfused with, which provides\nto the task.\n\nThis is to be used with external tasks defined in\n.\n\n@example Parameterizing a task config file with vars\nA var may be statically passed like so:\n\n```yaml\njobs:\n- name: task-vars\n  plan:\n  - get: ci\n  - task: override-task-vars\n    file: ci/tasks/print-var.yml\n    vars: # statically defined vars\n      my-var: \"Cookies are the best\"\n      second-var: \"chips are a close second\"\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```\n\nWhen run with the following:\n\n\n\nThe`\"((my-var))\"`will be resolved to`\"Cookies are the\n          best\"`and`((second-var))`will be resolved to`\"chips are\n          a close second\"`.\n\nThis can also be used in combination withfrom a\n(i.e. Vault) as a way to re-map\nvariable names to match what the task is expecting:\n\n```yaml\njobs:\n- name: task-vars\n  plan:\n  - get: ci\n  - task: override-task-vars\n    file: ci/tasks/print-var.yml\n    vars: # re-mapped vars\n      my-var: ((var-from-vault))\n      second-var: ((apple.type))\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/vars"
        },
        "input_mapping": {
          "description": "A map from task input names to concrete names in the build plan. This\nallows a task with generic input names to be used multiple times in the\nsame plan, mapping its inputs to specific resources within the plan.\n\n@example Generic task input names\nThe following example demonstrates a task with generic`main`\nand`dev`inputs being mapped to more specific artifact names,\n`repo`and`repo-dev`:\n\n```yaml\njobs:\n- name: task-input-mapping\n  plan:\n  - in_parallel:\n    - get: repo\n    - get: repo-dev\n    - get: ci\n  - task: list-inputs\n    input_mapping:\n      main: repo\n      dev: repo-dev\n    file: ci/tasks/generic-inputs.yml\n\nresources:\n- name: repo\n  type: mock\n- name: repo-dev\n  type: mock\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "$ref": "#/definitions/\\{input.name: identifier\\}"
        },
        "config": {
          "description": "Theto execute.\n@example Task config\n```yaml\njobs:\n- name: job\n  public: true\n  plan:\n  - task: simple-task\n    config: # contains all field in a task config\n      platform: linux\n      image_resource:\n        type: registry-image\n        source: { repository: busybox }\n      run:\n        path: echo\n        args: [\"Hello world!\"]\n```",
          "$ref": "#/definitions/task_config"
        }
      }
    },
    "dir_path": {
      "type": "string"
    },
    "load_var_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "file": {
          "description": "The path to a file whose content shall be read and used as the var's\nvalue.",
          "$ref": "#/definitions/file_path"
        },
        "format": {
          "description": "The format of the file's content.\n\nIf unset, Concourse will try to detect the format from the file\nextension. If the file format cannot be determined, Concourse will\nfallback to`trim`.\n\nIf set to`json`,`yaml`, or`yml`, the file content\nwill be parsed accordingly and the resulting structure will be the\nvalue of the var.\n\nIf set to`trim`, the var will be set to the content of the file\nwith any trailing and leading whitespace removed.\n\nIf set to`raw`, the var will be set to the content of the file\nwithout modification (i.e. with any existing whitespace).\n\n@example Loading a var with multiple fields\nLet's say we have a file with multiple fields, like this yaml file:\n\n\n\nWe could pass these values to subsequent steps by loading it\ninto a var with`load_var`, which will detect that it is in YAML\nformat based on the file extension:\n\n```yaml\njobs:\n- name: loading-vars\n  plan:\n  - get: examples\n  - load_var: version\n    file: examples/pipelines/vars-file.yml\n  - put: img\n    params:\n      version: \"((.:version.hello))-((.:version.number))\"\n\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n- name: img\n  type: mock\n```\n\nIf the file`vars-file.yml`was generated in a task and printed\nthese values, they would be automatically redacted unless\nis set.",
          "type": "string",
          "enum": [
            "json",
            "yaml",
            "yml",
            "trim",
            "raw"
          ]
        },
        "reveal": {
          "description": "If set to`true`, allow the var's\ncontent to be printed in the build output even with secret redaction\nenabled.",
          "$ref": "#/definitions/boolean"
        },
        "load_var": {
          "description": "The identifier will be the name of var, available to subsequent steps\nas a.\n\n@example Loading a simple value as a var\nThe following pipeline loads vars from a text file whose contents are\nused as a version number to.\n\n```yaml\njobs:\n- name: loading-vars\n  plan:\n  - get: examples\n  - load_var: version\n    file: examples/misc/simple-value.txt\n  - put: img\n    params:\n      version: ((.:version))\n\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n- name: img\n  type: mock\n```\n\n`simple-value.txt`looks like this:",
          "$ref": "#/definitions/identifier"
        }
      }
    },
    "identifier": {
      "type": "string"
    },
    "put_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "put": {
          "description": "When the step succeeds, the version by the step will be immediately\nfetched via an additional implicit. This is so\nthat later steps in your plan can use the artifact that was produced.\nThe artifact will be available under the identifier`put`\nspecifies.\n\n@example Getting and Putting\nThe following plan fetches a version using\nand pushes it to another resource\nusing:\n\n```yaml\njobs:\n- name: get-and-pull\n  plan:\n  - get: the-ice\n  - put: cyberdeck\n    params:\n      file: the-ice/version.txt\n\nresources:\n- name: the-ice\n  type: mock\n  source:\n    create_files:\n      version.txt: \"made-via-source\"\n- name: cyberdeck\n  type: mock\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/resource.name"
            },
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "params": {
          "description": "Arbitrary configuration to pass to the resource. Refer to the resource\ntype's documentation to see what it supports.\n\n@example Putting with params\n```yaml\njobs:\n- name: resource-params\n  plan:\n  - put: cyberdeck\n    params:\n      version: \"made-via-params\"\n\nresources:\n- name: cyberdeck\n  type: mock\n```",
          "$ref": "#/definitions/config"
        },
        "inputs": {
          "description": "When not set, or set to`all`, all\nartifacts will be provided. This can result in slow performance if the\nprior steps in the build plan register a bunch of large artifacts\nbefore this step, so you may want to consider being explicit.\n\nIf configured as a list of identifiers, only the listed artifacts will\nbe provided to the container.\n\nIf set to`detect`, the artifacts are detected based on the\nconfiguredby looking for all string values\nand using the first path segment as an identifier. (This may become the\ndefault in the future.)\n\n@example Put Input Methods\n```yaml\njobs:\n- name: put-input-methods\n  plan:\n  - in_parallel:\n    - get: repo-dev\n    - get: repo-master\n    - get: app-image\n    - get: ci\n  - put: all-inputs\n    resource: repo\n    inputs: all # default option\n    params:\n      file: ci/version.txt\n  - put: detect-inputs\n    resource: repo\n    inputs: detect # will only stream the \"ci\" artifact\n    params:\n      file: ci/version.txt\n  - put: explicit-inputs\n    resource: repo\n    inputs: # explicitly list artifacts to stream to put step\n      - ci\n    params:\n      file: ci/version.txt\n\nresources:\n- name: repo\n  type: mock\n- name: repo-dev\n  type: mock\n- name: repo-master\n  type: mock\n- name: app-image\n  type: mock\n- name: ci\n  type: mock\n  source:\n    create_files:\n      version.txt: \"42\"\n```",
          "oneOf": [
            {
              "type": "string",
              "enum": [
                "all"
              ]
            },
            {
              "type": "string",
              "enum": [
                "detect"
              ]
            },
            {
              "type": "array",
              "items": {
                "$ref": "#/definitions/identifier"
              }
            }
          ]
        },
        "get_params": {
          "description": "Arbitrary configuration to pass to the resource during the implicit\n`get`step. Refer to the resource type's documentation to see what\nit supports.\n\n@example Parameterizing the implicit`get`\nYou can control the settings of the implicit`get`step\nby setting`get_params`. For example, if you did not want a`put`\nstep utilizing theto download the\nimage, you would implement your`put`step as such:\n\n```yaml\nplan:\n- put: app-image\n  params:\n    build: git-resource\n  get_params:\n    skip_download: true\n```",
          "$ref": "#/definitions/config"
        },
        "resource": {
          "description": "The resource to update,\nas configured in.\n\n@example Re-label Put Resource\n```yaml\njobs:\n- name: fetch-repo\n  plan:\n    # puts to \"repo\" and fetches new version under artifact name \"thecode\"\n  - put: thecode\n    resource: repo\n    params:\n      version: put-only\n  - task: ls-repo\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      # pass the \"thecode\" artifact into the task\n      inputs:\n      - name: thecode\n      run:\n        path: ls\n        args: [\"-lah\",\"thecode\"]\n\nresources:\n- name: repo\n  type: mock\n```",
          "$ref": "#/definitions/resource.name"
        }
      }
    },
    "vault_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "namespace": {
          "description": "A\nto operate under.",
          "$ref": "#/definitions/string"
        },
        "client_token": {
          "description": "Authenticate via a periodic client token.\n\nSeefor more information.",
          "$ref": "#/definitions/string"
        },
        "shared_path": {
          "description": "An additional path under which credentials will be looked up.\n\nSeefor more information.",
          "$ref": "#/definitions/string"
        },
        "lookup_templates": {
          "description": "A list of path templates to be expanded in a team and pipeline context\nsubject to the`path_prefix`and`namespace`.\n\nSeefor more information.",
          "type": "array",
          "items": {
            "description": "A list of path templates to be expanded in a team and pipeline context\nsubject to the`path_prefix`and`namespace`.\n\nSeefor more information.",
            "$ref": "#/definitions/string"
          }
        },
        "ca_cert": {
          "description": "The PEM encoded contents of a CA certificate to use when\nconnecting to the API.",
          "$ref": "#/definitions/string"
        },
        "auth_params": {
          "description": "A key-value map of parameters to pass during authentication.\n\nSeefor more information.",
          "$ref": "#/definitions/\\{string: string\\}"
        },
        "url": {
          "description": "The URL of the Vault API.",
          "$ref": "#/definitions/string"
        },
        "auth_retry_initial": {
          "description": "When retrying during authentication, start with this retry\ninterval. The interval will increase exponentially until\n`auth_retry_max`is reached.",
          "$ref": "#/definitions/duration"
        },
        "client_key": {
          "description": "A PEM encoded client key, for use with TLS based auth.\n\nSeefor more information.",
          "$ref": "#/definitions/string"
        },
        "auth_backend": {
          "description": "Authenticate using an auth backend, e.g.`cert`or\n`approle`.\n\nSeeorfor\nmore information.",
          "$ref": "#/definitions/string"
        },
        "auth_max_ttl": {
          "description": "Maximum duration to elapse before forcing the client to log in\nagain.",
          "$ref": "#/definitions/duration"
        },
        "auth_retry_max": {
          "description": "When failing to authenticate, give up after this amount of\ntime.",
          "$ref": "#/definitions/duration"
        },
        "client_cert": {
          "description": "A PEM encoded client certificate, for use with TLS based auth.\n\nSeefor more information.",
          "$ref": "#/definitions/string"
        },
        "insecure_skip_verify": {
          "description": "Skip TLS validation. Not recommended. Don't do it. No really,\ndon't.",
          "$ref": "#/definitions/boolean"
        },
        "path_prefix": {
          "description": "A prefix under which to\nlook for all credential values.\n\nSeefor more information.",
          "$ref": "#/definitions/string"
        },
        "server_name": {
          "description": "The expected name of the server when connecting through TLS.",
          "$ref": "#/definitions/string"
        }
      }
    },
    "config": {
      "type": "object",
      "patternProperties": {
        ".*": {
          "additionalProperties": true
        }
      }
    },
    "anonymous_resource": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "params": {
          "description": "A map of arbitrary configuration to forward to the resource. Refer to the\nresource type's documentation to see what it supports.",
          "$ref": "#/definitions/config"
        },
        "source": {
          "description": "The configuration for the resource; see\n.",
          "$ref": "#/definitions/config"
        },
        "type": {
          "description": "The type of the resource. Usually`registry-image`.\n\nYou can use any resource type that returns a filesystem in the correct\nformat: a`/rootfs`directory containing a full filesystem, and a\n`metadata.json`file containing.",
          "$ref": "#/definitions/resource_type.name"
        },
        "version": {
          "description": "A specific version of the resource to fetch. This should be a map with\nstring keys and values. If not specified, the latest version will be\nfetched.",
          "$ref": "#/definitions/version"
        }
      }
    }
  }
}
