{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "$ref": "#/definitions/pipeline",
  "additionalProperties": true,
  "definitions": {
    "command": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "dir": {
          "description": "A directory, relative to the initial working directory, to set as theworking directory when running the script.",
          "oneOf": [
            {
              "$ref": "#/definitions/dir_path"
            }
          ]
        },
        "path": {
          "description": "The name of or path to the executable to run.\n\n\n\n`path`is relative to the working directory. If`dir`isspecified to set the working directory, then`path`is relative toit.\n\nThis is commonly a path to a script provided by one of the task's inputs,e.g.`my-resource/scripts/test`. It could also be a command like\n\n`bash`(respecting standard`$PATH`lookup rules), or an absolutepath to a file to execute, e.g.`/bin/bash`.",
          "oneOf": [
            {
              "$ref": "#/definitions/file_path"
            }
          ]
        },
        "args": {
          "description": "Arguments to pass to the command. Note that when executed with\n\nfly-cliFly, any arguments passed tofly-execute\n\nare appended to this array.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/string"
                  }
                ]
              }
            }
          ]
        },
        "user": {
          "description": "Explicitly set the user to run as. If not specified, this defaults to theuser configured by the task's image. If not specified there, it's up tothe Garden backend, and may be e.g.`root`on Linux.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        }
      }
    },
    "pipeline": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "jobs": {
          "description": "A set ofjobsjobsfor the pipeline to continuously schedule. At least one job is required for a pipeline to be valid.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/job"
                  }
                ]
              }
            }
          ]
        },
        "display": {
          "description": "`display`was introduced in Concourse v6.6.0. It is considered an\n\n**experimental**feature.\n\n\n\n\n\nVisual configurations for personalizing your pipeline.\n\n\n\n@example Background image\n\n\nThe following example will display an image in the background of the pipelineit is configured on.\n\n\n\n```yaml\ndisplay:\n  background_image: https://avatars1.githubusercontent.com/u/7809479?s=400&v=4\n```\n\n\n\n\n\n\n\n\n\ndisplay_config\n\n\n\nbackground_imagestring\n\nAllow users to specify a custom background image which is put at 30%opacity, grayscaled and blended into existing background. Must be anhttp, https, or relative URL.",
          "oneOf": [
            {
              "$ref": "#/definitions/display_config"
            }
          ]
        },
        "resource_types": {
          "description": "A set ofresource-typesresource typesfor resources within thepipeline to use.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/resource_type"
                  }
                ]
              }
            }
          ]
        },
        "resources": {
          "description": "A set ofresourcesresourcesfor the pipeline to continuouslycheck.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/resource"
                  }
                ]
              }
            }
          ]
        },
        "var_sources": {
          "description": "A set ofvar-sourcesfor the pipeline to use.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/var_source"
                  }
                ]
              }
            }
          ]
        },
        "groups": {
          "description": "A list of job groups to use for organizing jobs in the web UI.\n\nGroups have no functional effect on your pipeline. They are purely formaking it easier to grok large pipelines in the web UI.\n\nNote: once you have added groups to your pipeline, all jobs must be in agroup.\n\n\n\n@example Grouping jobs\n\n\nThe following example will make the \"tests\" group the default view (sinceit's listed first), separating the later jobs into a \"publish\" group:\n\n\n\n```yaml\ngroups:\n- name: test\n  jobs:\n  - unit\n  - integration\n- name: publish\n  jobs:\n  - deploy\n  - shipit\n```\n\n\n\nThis would display two tabs at the top of the home page: \"test\" and\"publish\".\n\nFor a real world example of how groups can be used to simplify navigationand provide logical grouping, see the groups used at the top of the pagein theConcourse pipelinehttps://ci.concourse-ci.org.\n\n\n\n\n\n\n\ngroup_config\n\n\n\nnameidentifier\n\nA unique name for the group. This should be short and simple as it willbe used as the tab name for navigation.\n\n\n\n\n\n\n\njobs[job.name]\n\nA list of jobs that should appear in this group. A job mayappear in multiple groups. Neighbours of jobs in the current group will alsoappear on the same page in order to give context of the location of thegroup in the pipeline.\n\nYou may also use any validglobhttps://www.man7.org/linux/man-pages/man7/glob.7.html\n\nto represent several jobs, e.g.:\n\n\n\n```yaml\ngroups:\n- name: develop\n  jobs:\n  - terraform-*\n  - test\n  - deploy-{dev,staging}\n- name: ship\n  jobs:\n  - deploy-prod\n- name: all\n  jobs:\n  - \"*\"\n```\n\n\n\nIn this example, the`develop`group will match\n\n`terraform-apply`,`terraform-destroy`,`test`,\n\n`deploy-dev`,`deploy-staging`. The`ship`group will only match\n\n`deploy-prod`. The`all`group will match all jobs in the pipeline.\n\n\n\nNote that depending on how it's used,`*`,`{`, and\n\n`}`have special meaning in YAML, and may need to be quoted (aswas done in the`all`job above)",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/group_config"
                  }
                ]
              }
            }
          ]
        }
      }
    },
    "do_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "do": {
          "description": "@example Running multiple steps in a try\n\n\nThis can be used to perform multiple steps serially in a\n\ntry-step:\n\n\n\n```yaml\njobs:\n- name: with-do\n  plan:\n  - try:\n      do:\n      - get: black-ice\n      - get: control-node\n      - get: cyberdeck\n\nresources:\n- name: black-ice\n  type: mock\n- name: control-node\n  type: mock\n- name: cyberdeck\n  type: mock\n```",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/step"
                  }
                ]
              }
            }
          ]
        }
      }
    },
    "input": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "optional": {
          "description": "Default`false`.If`true`, then the input is notrequired by the task. The task may run even if this input is missing.\n\nAn`optional`input that is missing will not appear in the currentdirectory of the running task.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "name": {
          "description": "The name of the input.",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "path": {
          "description": "The path where the input will be placed. If not specified, the input's\n\n`name`is used.\n\nPaths are relative to the working directory of the task. Absolute pathsare not respected.",
          "oneOf": [
            {
              "$ref": "#/definitions/dir_path"
            }
          ]
        }
      }
    },
    "boolean": {
      "type": "boolean"
    },
    "get_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "passed": {
          "description": "When specified, only the versions of the resource that made it throughthe given list of jobs (AND-ed together) will be considered whentriggering and fetching.\n\n\n\n@example Fanning out and in\n\n\nIf multiple`get`s are configured with`passed`\n\nconstraints, all of the mentioned jobs are correlated.\n\n\n\n```yaml\njobs:\n- name: lvl-1-firewall\n  plan:\n  - in_parallel:\n    - get: black-ice\n    - get: control-node\n    - get: cyberdeck\n\n- name: lvl-2-unit\n  plan:\n  - in_parallel:\n    - get: black-ice\n      passed: [lvl-1-firewall]\n    - get: control-node\n      passed: [lvl-1-firewall]\n    - get: cyberdeck\n      passed: [lvl-1-firewall]\n\n- name: lvl-2-integration\n  plan:\n  - in_parallel:\n    - get: black-ice\n      passed: [lvl-1-firewall]\n    - get: control-node\n      passed: [lvl-1-firewall]\n    - get: cyberdeck\n      passed: [lvl-1-firewall]\n\n- name: lvl-3-production\n  plan:\n  - in_parallel:\n    - get: black-ice\n      passed: [lvl-2-unit,lvl-2-integration]\n    - get: control-node\n      passed: [lvl-2-unit,lvl-2-integration]\n    - get: cyberdeck\n      passed: [lvl-2-unit,lvl-2-integration]\n\nresources:\n- name: black-ice\n  type: mock\n  source:\n    initial_version: lvl4\n- name: control-node\n  type: mock\n  source:\n    initial_version: tower\n- name: cyberdeck\n  type: mock\n  source:\n    initial_version: mk3\n```\n\n\n\nFor the final job,`lvl-3-production`, only versions that havepassed the previous two jobs (`lvl-2-unit`and\n\n`lvl-2-integration`) will be passed to`lvl-3-production`.\n\nThis is crucial to being able to implement safe \"fan-in\" semantics asthings progress through a pipeline.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/string"
                  }
                ]
              }
            }
          ]
        },
        "get": {
          "description": "The fetched bits will be registered in the build's artifact namespaceunder the given identifier. Subsequenttask-stepand\n\nput-stepwhich list the identifier as an input will have acopy of the bits in their working directory.\n\n\n\n@example Fetching a repo and passing it to a task\n\n\nAlmost every simple job will look something like this: fetch my codewith aget-stepand do something (run tests) with it in a\n\ntask-step.\n\n\n\n```yaml\njobs:\n- name: fetch-repo\n  plan:\n  - get: repo # fetches repo under artifact name \"repo\"\n  - task: ls-repo\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      # pass the \"repo\" artifact into the task\n      inputs:\n      - name: repo\n      run:\n        path: ls\n        args: [\"-lah\",\"repo\"]\n\nresources:\n- name: repo\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            },
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "resource": {
          "description": "Defaults to the value of`get`.The resource to fetch,as configured inschema.pipeline.resources.\n\nUse this attribute to rename a resource from the overall pipeline contextinto the job-specific context.\n\n\n\n@example Re-labelling artifact\n\n\n\n\n```yaml\njobs:\n- name: fetch-repo\n  plan:\n  - get: thecode # fetches \"repo\" under artifact name \"thecode\"\n    resource: repo\n  - task: ls-repo\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      # pass the \"thecode\" artifact into the task\n      inputs:\n      - name: thecode\n      run:\n        path: ls\n        args: [\"-lah\",\"thecode\"]\n\nresources:\n- name: repo\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "params": {
          "description": "Arbitrary configuration to pass to the resource. Refer to the resourcetype's documentation to see what it supports.\n\n\n\n@example Fetching with`params`\n\n\n\n\n```yaml\njobs:\n- name: resource-params\n  plan:\n  - get: cyberdeck\n    params:\n      create_files_via_params:\n        version_to_put.txt: \"made-via-params\"\n  - put: cyberdeck\n    params:\n      file: cyberdeck/version_to_put.txt\n\n\nresources:\n- name: cyberdeck\n  type: mock\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/config"
            }
          ]
        },
        "trigger": {
          "description": "Default`false`.If set to`true`, new builds of thejob will be automatically created when a new version for this inputbecomes available.\n\nNote: if none of a job's`get`steps are set to`true`, thejob can only be manually triggered.\n\n\n\n@example Automatically trigger job on new versions\n\n\n\n\n\n\n```yaml\njobs:\n- name: fetch-repo\n  plan:\n  - get: repo\n    trigger: true # automatically runs the job\n  - task: ls-repo\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      inputs:\n      - name: repo\n      run:\n        path: ls\n        args: [\"-lah\",\"repo\"]\n\nresources:\n- name: repo\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "version": {
          "description": "Default`latest`.The version of the resource to fetch.\n\nIf set to`latest`, scheduling will just find the latest availableversion of a resource and use it, allowing versions to be skipped.  This isusually what you want, e.g. if someone pushes 100 git commits.\n\nIf set to`every`, builds will walk through all available versions ofthe resource. Note that if`passed`is also configured, it will onlystep through the versions satisfying the constraints.\n\nIf set to a specific version (e.g.`{ref: abcdef123}`), only thatversion will be used. Note that the version must be available and detected bythe resource, otherwise the input will never be satisfied. You may want tousefly-check-resourceto force detection of resource versions,if you need to use an older one that was never detected (as all newlyconfigured resources start from the latest version).",
          "oneOf": [
            {
              "type": "string",
              "enum": [
                "latest"
              ]
            },
            {
              "type": "string",
              "enum": [
                "every"
              ]
            },
            {
              "$ref": "#/definitions/version"
            }
          ]
        }
      }
    },
    "load_var_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "load_var": {
          "description": "The identifier will be the name of var, available to subsequent stepsas alocal-varslocal build var.\n\n\n\n@example Loading a simple value as a var\n\n\nThe following pipeline loads vars from a text file whose contents areused as a version number toput-step`put`.\n\n\n\n```yaml\njobs:\n- name: loading-vars\n  plan:\n  - get: examples\n  - load_var: version\n    file: examples/misc/simple-value.txt\n  - put: img\n    params:\n      version: ((.:version))\n\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n- name: img\n  type: mock\n```\n\n\n\n\n\n`simple-value.txt`looks like this:\n\nhttps://raw.githubusercontent.com/concourse/examples/master/misc/simple-value.txt",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "file": {
          "description": "The path to a file whose content shall be read and used as the var'svalue.",
          "oneOf": [
            {
              "$ref": "#/definitions/file_path"
            }
          ]
        },
        "reveal": {
          "description": "Default`false`.If set to`true`, allow the var'scontent to be printed in the build output even with secret redactionenabled.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "format": {
          "description": "The format of the file's content.\n\nIf unset, Concourse will try to detect the format from the fileextension. If the file format cannot be determined, Concourse willfallback to`trim`.\n\nIf set to`json`,`yaml`, or`yml`, the file contentwill be parsed accordingly and the resulting structure will be thevalue of the var.\n\nIf set to`trim`, the var will be set to the content of the filewith any trailing and leading whitespace removed.\n\nIf set to`raw`, the var will be set to the content of the filewithout modification (i.e. with any existing whitespace).\n\n\n\n@example Loading a var with multiple fields\n\n\nLet's say we have a file with multiple fields, like this yaml file:\n\n\n\nyamlhttps://raw.githubusercontent.com/concourse/examples/master/pipelines/vars-file.yml\n\n\n\nWe could pass these values to subsequent steps by loading itinto a var with`load_var`, which will detect that it is in YAMLformat based on the file extension:\n\n\n\n```yaml\njobs:\n- name: loading-vars\n  plan:\n  - get: examples\n  - load_var: version\n    file: examples/pipelines/vars-file.yml\n  - put: img\n    params:\n      version: \"((.:version.hello))-((.:version.number))\"\n\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n- name: img\n  type: mock\n```\n\n\n\nIf the file`vars-file.yml`was generated in a task and printedthese values, they would be automatically redacted unless\n\nschema.load-var.reveal`reveal: true`is set.",
          "type": "string",
          "enum": [
            "json",
            "yaml",
            "yml",
            "trim",
            "raw"
          ]
        }
      }
    },
    "set_pipeline_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "vars": {
          "description": "A map of template variables to pass to the pipeline config. Unlike\n\nschema.set-pipeline.instance_vars`instance_vars`,\n\n`vars`are solely used to for\n\npipeline-static-varsinterpolation, and do not become a part ofthe pipeline's identifier.\n\nNote that variables set with this field will not propagate to tasks configuredviaschema.task.file. If you want those variables to be determinedat the time the pipeline is set, useschema.task.varsas well.\n\n\n\n@example Configuring static vars\n\n\n\n\n```yaml\njobs:\n- name: set-pipeline-vars-only\n  plan:\n  - get: examples\n  - set_pipeline: pipeline-set-with-vars\n    file: examples/pipelines/pipeline-vars.yml\n    vars:\n      first: initial\n      number: \"9000\"\n      hello: HAL\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/vars"
            }
          ]
        },
        "set_pipeline": {
          "description": "The identifier specifies the name of the pipeline to configure. Unless\n\nschema.set-pipeline.teamis set, it will be configuredwithin the current team and be createdunpaused. If set to`self`,the current pipeline will update its own config.\n\n\n\n\n\n\n\n`set_pipeline: self`was introduced in Concourse v6.5.0. It isconsidered an**experimental**feature and may be removed at anytime. Contribute to the associated\n\ndiscussionhttps://github.com/concourse/concourse/discussions/5732\n\nwith feedback.\n\n\n\n\n\n\n\n\n\n@example One pipeline configuring another\n\n\nThis is a way to ensure a pipeline stays up to date with its definition ina source code repository, eliminating the need to manually run\n\nfly-set-pipeline.\n\n\n\n```yaml\njobs:\n- name: set-pipeline\n  plan:\n  - get: examples\n    trigger: true\n  - set_pipeline: hello-world  # pipeline's name\n    file: examples/pipelines/hello-world.yml  # pipeline's config\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            },
            {
              "type": "string",
              "enum": [
                "self"
              ]
            }
          ]
        },
        "var_files": {
          "description": "A list of paths to`.yml`files that will be passed to thepipeline config in the same manner as the`--load-vars-from`flagtofly-set-pipeline. This means that if a variable appearsin multiple files, the value from a file that is passed later in thelist will override the values from files earlier in the list.\n\n\n\n@example Configuring static vars with a vars file\n\n\nWhere the vars file looks like:\n\nyamlhttps://raw.githubusercontent.com/concourse/examples/master/pipelines/vars-file.yml\n\n\n\nAnd the pipeline config is:\n\n\n\n```yaml\njobs:\n- name: set-pipeline-vars-only\n  plan:\n  - get: examples\n  - set_pipeline: pipeline-set-with-vars\n    file: examples/pipelines/pipeline-vars.yml\n    var_files:\n      - examples/pipelines/vars-file.yml\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/file_path"
                  }
                ]
              }
            }
          ]
        },
        "file": {
          "description": "The path to the pipeline's configuration file.\n\n\n\n`file`points at a`.yml`file containing the pipelineconfiguration, which allows this to be tracked with your resources orgenerated by atask-step.\n\nThe first segment in the path should refer to another artifact from theplan, and the rest of the path is relative to that artifact.\n\n\n\n@example Fetching and configuring a pipeline\n\n\nTheget-stepcan be used to fetch your configuration froma`git`repo and auto-configure it using a\n\nset-pipeline-step:\n\n\n\n```yaml\njobs:\n- name: set-pipeline\n  plan:\n  - get: examples\n    trigger: true\n  - set_pipeline: hello-world  # pipeline's name\n    file: examples/pipelines/hello-world.yml  # pipeline's config\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/file_path"
            }
          ]
        },
        "instance_vars": {
          "description": "A map of instance vars used to identify\n\ninstanced-pipelinesinstanced pipelines. These vars will also be\n\npipeline-static-varsinterpolated into the pipeline config.\n\nNote that variables set with this field will not propagate to tasks configuredviaschema.task.file. If you want those variables to be determinedat the time the pipeline is set, useschema.task.varsas well.\n\n\n\n\n\n\n\ninstanced-pipelinesInstance pipelinesare experimentaland need to be enabled by setting the\n\n`--enable-pipeline-instances`flag on theweb-node.\n\n\n\n\n\n\n\n@example Configuring instance vars\n\n\nThe following pipeline will create one instance group with threepipelines. The instance group is called`my-bots`and eachpipeline has a different set of`instance_vars`making itdistinct from the other pipelines in the instance group.\n\n```yaml\njobs:\n- name: set-pipeline-instance-group\n  plan:\n  - get: examples\n  - in_parallel:\n    - set_pipeline: my-bots\n      file: examples/pipelines/pipeline-vars.yml\n      instance_vars:\n        first: initial\n        number: \"9000\"\n        hello: HAL\n    - set_pipeline: my-bots\n      file: examples/pipelines/pipeline-vars.yml\n      instance_vars:\n        first: second\n        number: \"3000\"\n        hello: WALLY-E\n    - set_pipeline: my-bots\n      file: examples/pipelines/pipeline-vars.yml\n      instance_vars:\n        first: the-third\n        number: \"6000\"\n        hello: R2D2\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```\n\n\n\n\n\n\n\n@example Configuring instance vars and vars\n\n\nBoth`instance_vars`and`vars`may be statically. Thedifference between the two fields is that`instance_vars`areused to identify a pipeline and render the pipeline config.\n\n`vars`are only used for rendering the pipeline config:\n\n\n\n```yaml\njobs:\n- name: set-pipeline-vars-and-instance-vars\n  plan:\n  - get: examples\n  - set_pipeline: my-bots\n    file: examples/pipelines/pipeline-vars.yml\n    instance_vars:\n      first: initial\n      number: \"9000\"\n    vars:\n      hello: HAL\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/vars"
            }
          ]
        },
        "team": {
          "description": "By default, the`set_pipeline`step sets the pipeline for thesameteamsteamthat is running the build.\n\nThe`team`attribute can be used to specify another team.\n\nOnly themain-teamis allowed to set another team'spipeline.  Any team other than themain-teamusing the\n\n`team`attribute will error, unless they reference their own team.\n\n\n\n\n\nThe`team`attribute was introduced in Concourse v6.4.0. It isconsidered an**experimental**feature and may be removed at anytime. Contribute to the associated\n\ndiscussionhttps://github.com/concourse/concourse/discussions/5731\n\nwith feedback.\n\n\n\n\n\n\n\n@example Setting a pipeline on another team\n\n\n\n\n```yaml\njobs:\n- name: set-pipeline\n  plan:\n  - get: examples\n    trigger: true\n  - set_pipeline: hello-world\n    file: examples/pipelines/hello-world.yml\n    team: other-team  # name of the team goes here\n\nresources:\n- name: examples\n  type: git\n  icon: github\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        }
      }
    },
    "build_log_retention_policy": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "days": {
          "description": "Keep logs for builds which have finished within the specified number ofdays.",
          "oneOf": [
            {
              "$ref": "#/definitions/number"
            }
          ]
        },
        "minimum_succeeded_builds": {
          "description": "Keep a minimum number of successful build logs that would normally bereaped.\n\nRequires\n\nschema.build_log_retention_policy.builds`builds`tobe set to an integer higher than 0 in order to work. For example, if\n\nschema.build_log_retention_policy.builds`builds`isset to 5, and this attribute to 1, say a job has the following buildhistory: 7(f), 6(f), 5(f), 4(f), 3(f), 2(f), 1(s), where f meansfailed and s means succeeded, then builds 2 and 3 will be reaped,because it retains 5 build logs, and at least 1 succeeded build log.Default is 0.",
          "oneOf": [
            {
              "$ref": "#/definitions/number"
            }
          ]
        },
        "builds": {
          "description": "Keep logs for the last specified number of builds.",
          "oneOf": [
            {
              "$ref": "#/definitions/number"
            }
          ]
        }
      }
    },
    "value": {
      "type": "object",
      "patternProperties": {
        ".*": {
          "additionalProperties": true
        }
      }
    },
    "across_var": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "fail_fast": {
          "description": "Default`false`.When enabled, the`across`step willfail fast by returning as soon as any sub-step fails. This means that running stepswill be interrupted and pending steps will no longer be scheduled.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "values": {
          "description": "The list of values that theschema.across_var.varvarwilliterate over when running the substep. If multipleschema.across_varvars\n\nare configured, all combinations of values across all vars will run.\n\nThe list of values may also be interpolated. For instance, you may usetheload-var-stepto first load a list ofschema.value\n\ninto alocal-varslocal var, and then iterate across that dynamiclist of values.\n\n\n\n@example Value combinations\n\n\nThe followingschema.acrosswill run the task\n\n`foo/build.yml`for each package defined in`foo/packages-to-build.json`\n\nwith Go 1.15 and 1.16.\n\n\n\n```yaml\nplan:\n- get: foo\n- load_var: packages\n  file: foo/packages-to-build.json\n- across:\n  - var: package\n    values: ((.:packages))\n  - var: go_version\n    values: ['1.15', '1.16']\n  task: build\n  file: foo/build.yml\n  vars:\n    go_version: ((.:go_version))\n    package: ((.:package))\n```\n\n\n\nSupposing`foo/packages-to-build.json`had the following content:\n\n```json\n[\"./cmd/first\", \"./cmd/second\", \"./cmd/third\"]\n```\n\n\n\n...then the task`foo/build.yml`would be run with the followingvar combinations:\n\n\n\n\n\n\n\n`{package: \"./cmd/first\", go_version: \"1.15\"}`\n\n\n\n\n\n\n\n`{package: \"./cmd/first\", go_version: \"1.16\"}`\n\n\n\n\n\n\n\n`{package: \"./cmd/second\", go_version: \"1.15\"}`\n\n\n\n\n\n\n\n`{package: \"./cmd/second\", go_version: \"1.16\"}`\n\n\n\n\n\n\n\n`{package: \"./cmd/third\", go_version: \"1.15\"}`\n\n\n\n\n\n\n\n`{package: \"./cmd/third\", go_version: \"1.16\"}`",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/value"
                  }
                ]
              }
            }
          ]
        },
        "var": {
          "description": "The name of the variable that will be added to the\n\nlocal-vars\"`.`\" var source. This variable will only beaccessible in the scope of the step - each iteration of the step getsits own scope.\n\nIf a variable of the same name already exists in the parent scope, awarning will be printed.",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "max_in_flight": {
          "description": "Default`1`.If set to`all`, the substep will runwith all combinations of the current var in parallel. If set to a\n\nschema.number, only that number of substeps may run in parallel.\n\n\n\n@example Multiple vars\n\n\nIf multipleschema.across_varvarsare configured, theeffective`max_in_flight`is multiplicative. For instance:\n\n\n\n```yaml\nplan:\n- across:\n  - var: var1\n    values: [a, b, c]\n    max_in_flight: all\n  - var: var2\n    values: [1, 2]\n  - var: var3\n    values: [foo, bar]\n    max_in_flight: 2\n```\n\n\n\nHere,**6 substeps**will run in parallel, since all 3 of\n\n`var1`'s values can run in parallel, and 2 of`var3`'svalues can run in parallel.",
          "oneOf": [
            {
              "type": "string",
              "enum": [
                "all"
              ]
            },
            {
              "$ref": "#/definitions/number"
            }
          ]
        }
      }
    },
    "file_path": {
      "type": "string"
    },
    "duration": {
      "type": "string"
    },
    "in_parallel_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "in_parallel": {
          "description": "Steps are either configured as a array or within an\n\nschema.in_parallel_config.\n\n\n\n@example Fetching artifacts in parallel\n\n\nUsing the`in_parallel`step where possible is the easiest wayto speeding up a builds.\n\nIt is often used to fetch all dependent resources together at thestart of a build plan:\n\n\n\n```yaml\njobs:\n- name: get-in-parallel\n  plan:\n  - in_parallel:\n    - get: ci\n    - get: repo\n    - get: code\n\n\nresources:\n- name: repo\n  type: mock\n- name: code\n  type: mock\n- name: ci\n  type: mock\n```\n\n\n\n\n\n\n\n\n\n@example Running a build matrix\n\n\nIf any step in the`in_parallel`fails, the build will fail, making ituseful for build matrices:\n\n\n\n```yaml\nplan:\n- get: some-repo\n- in_parallel:\n  - task: unit-windows\n    file: some-repo/ci/windows.yml\n  - task: unit-linux\n    file: some-repo/ci/linux.yml\n  - task: unit-darwin\n    file: some-repo/ci/darwin.yml\n```",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/step"
                  }
                ]
              }
            },
            {
              "$ref": "#/definitions/in_parallel_config"
            }
          ]
        }
      }
    },
    "job": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "plan": {
          "description": "The sequence ofstepsstepsto execute.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/step"
                  }
                ]
              }
            }
          ]
        },
        "on_success": {
          "description": "Step to execute when the job succeeds. Equivalent to the\n\nschema.on_successhook.",
          "oneOf": [
            {
              "$ref": "#/definitions/step"
            }
          ]
        },
        "name": {
          "description": "The name of the job. This should be short; it will show up in URLs.",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "max_in_flight": {
          "description": "If set, specifies a maximum number of builds to run at a time. If\n\n`serial`or`serial_groups`are set, they take precedence andforce this value to be`1`.",
          "oneOf": [
            {
              "$ref": "#/definitions/number"
            }
          ]
        },
        "interruptible": {
          "description": "Default`false`.Normally, when a worker is shutting down itwill wait for builds with containers running on that worker to finishbefore exiting. If this value is set to`true`, the worker will notwait on the builds of this job. You may want this if e.g. you have aself-deploying Concourse or long-running-but-low-importance jobs.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "public": {
          "description": "Default`false`.If set to`true`, the build log of thisjob will be viewable by unauthenticated users. Unauthenticated users willalways be able to see the inputs, outputs, and build status history of ajob. This is useful if you would like to expose your pipeline publiclywithout showing sensitive information in the build log.\n\nNote: when this is set to`true`, anyget-stepand\n\nput-steps will show the metadata for their resource version,regardless of whether the resource itself has setschema.resource.public\n\nto`true`.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "serial_groups": {
          "description": "Default`[]`.When set to an array of arbitrary tag-likestrings, builds of this job and other jobs referencing the same tags willbe serialized.\n\n\n\n@example Limiting parallelism\n\n\nThis can be used to ensure that certain jobs do not run at the same time,like so:\n\n\n\n```yaml\njobs:\n- name: job-a\n  serial_groups: [some-tag]\n- name: job-b\n  serial_groups: [some-tag, some-other-tag]\n- name: job-c\n  serial_groups: [some-other-tag]\n```\n\n\n\nIn this example,`job-a`and`job-c`can run concurrently, butneither job can run builds at the same time as`job-b`.\n\nThe builds are executed in their order of creation, across all jobs withcommon tags.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/identifier"
                  }
                ]
              }
            }
          ]
        },
        "on_failure": {
          "description": "Step to execute when the job fails. Equivalent to the\n\nschema.on_failurehook.",
          "oneOf": [
            {
              "$ref": "#/definitions/step"
            }
          ]
        },
        "on_abort": {
          "description": "Step to execute when the job aborts. Equivalent to the\n\nschema.on_aborthook.",
          "oneOf": [
            {
              "$ref": "#/definitions/step"
            }
          ]
        },
        "ensure": {
          "description": "Step to execute regardless of whether the job succeeds, fails, errors, oraborts. Equivalent to theschema.ensurehook.",
          "oneOf": [
            {
              "$ref": "#/definitions/step"
            }
          ]
        },
        "build_log_retention": {
          "description": "Configures the retention policy for build logs. This is useful if you havea job that runs often but after some amount of time the logs aren't worthkeeping around.\n\nBuilds which are not retained by the configured policy will have their logsreaped. If this configuration is omitted, logs are kept forever (unless\n\nbuild-log-retentionis configured globally).\n\n\n\n@example A complicated example\n\n\nThe following example will keep logs for any builds that have completed inthe last 2 days, while also keeping the last 1000 builds and at least 1succeeded build.\n\n\n\n```yaml\njobs:\n- name: smoke-tests\n  build_log_retention:\n    days: 2\n    builds: 1000\n    minimum_succeeded_builds: 1\n  plan:\n  - get: 10m\n  - task: smoke-tests\n    # ...\n```\n\n\n\nIf more than 1000 builds finish in the past 2 days,allof themwill be retained thanks to the\n\nschema.build_log_retention_policy.days`days`\n\nconfiguration. Similarly, if there are 1000 builds spanning more than 2days, they will also be kept thanks to the\n\nschema.build_log_retention_policy.builds`builds`\n\nconfiguration. And if they all happened to have failed, the\n\nschema.build_log_retention_policy.minimum_succeeded_builds`minimum_succeeded_builds`\n\nwill keep around at least one successful build. All policies operateindependently.\n\n\n\n\n\n\n\nbuild_log_retention_policy\n\n\n\ndaysnumber\n\nKeep logs for builds which have finished within the specified number ofdays.\n\n\n\n\n\n\n\nbuildsnumber\n\nKeep logs for the last specified number of builds.\n\n\n\n\n\n\n\nminimum_succeeded_buildsnumber\n\nKeep a minimum number of successful build logs that would normally bereaped.\n\nRequires\n\nschema.build_log_retention_policy.builds`builds`tobe set to an integer higher than 0 in order to work. For example, if\n\nschema.build_log_retention_policy.builds`builds`isset to 5, and this attribute to 1, say a job has the following buildhistory: 7(f), 6(f), 5(f), 4(f), 3(f), 2(f), 1(s), where f meansfailed and s means succeeded, then builds 2 and 3 will be reaped,because it retains 5 build logs, and at least 1 succeeded build log.Default is 0.",
          "oneOf": [
            {
              "$ref": "#/definitions/build_log_retention_policy"
            }
          ]
        },
        "build_logs_to_retain": {
          "description": "Deprecated.Equivalent to setting\n\nschema.build_log_retention_policy.builds`job.build_log_retention.builds`.",
          "oneOf": [
            {
              "$ref": "#/definitions/number"
            }
          ]
        },
        "serial": {
          "description": "Default`false`.If set to`true`, builds will queue upand execute one-by-one, rather than executing in parallel.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "old_name": {
          "description": "The old name of the job. If configured, the history of old job will beinherited to the new one. Once the pipeline is set, this field can beremoved as the builds have been transfered.\n\n\n\n@example Renaming a job\n\n\nThis can be used to rename a job without losing its history, like so:\n\n\n\n```yaml\njobs:\n- name: new-name\n  old_name: current-name\n  plan: [{get: 10m}]\n```\n\n\n\nAfter the pipeline is set, because the builds have been inherited, the job canhave the field removed:\n\n\n\n```yaml\njobs:\n- name: new-name\n  plan: [{get: 10m}]\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "on_error": {
          "description": "Step to execute when the job errors. Equivalent to the\n\nschema.on_errorhook.",
          "oneOf": [
            {
              "$ref": "#/definitions/step"
            }
          ]
        },
        "disable_manual_trigger": {
          "description": "Default`false`.If set to`true`, manual triggering ofthe job (via the web UI orfly-trigger-job) will be disabled.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        }
      }
    },
    "anonymous_resource": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "source": {
          "description": "The configuration for the resource; see\n\nschema.resource.source.",
          "oneOf": [
            {
              "$ref": "#/definitions/config"
            }
          ]
        },
        "type": {
          "description": "The type of the resource. Usually`registry-image`.\n\nYou can use any resource type that returns a filesystem in the correctformat: a`/rootfs`directory containing a full filesystem, and a\n\n`metadata.json`file containing.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "params": {
          "description": "A map of arbitrary configuration to forward to the resource. Refer to theresource type's documentation to see what it supports.",
          "oneOf": [
            {
              "$ref": "#/definitions/config"
            }
          ]
        },
        "version": {
          "description": "A specific version of the resource to fetch. This should be a map withstring keys and values. If not specified, the latest version will befetched.",
          "oneOf": [
            {
              "$ref": "#/definitions/version"
            }
          ]
        }
      }
    },
    "task_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "rootfs_uri": {
          "description": "A string specifying the rootfs uri of the container, as interpreted by yourworker's Garden backend.\n\n\n\nschema.task-config.image_resourceis the preferred way to specify base image.You should only use this if you have no other option and you really knowwhat you're doing.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "caches": {
          "description": "The cached directories shared between task runs.\n\nOn the task's first run, all cache directories will be empty. It is theresponsibility of the task to populate these directories with any artifactsto be cached. On subsequent runs, the cached directories will contain thoseartifacts.\n\nCaches are scoped to the worker the task is run on, so you will not get acache hit when subsequent builds run on different workers. This also meansthat caching is not intended to share state between workers, and your taskshould be able to run whether or not the cache is warmed.\n\nCaches are also scoped to a particular task name inside of a pipeline'sjob. As a consequence, if the job name, step name or cache path arechanged, the cache will not be used. This also means that caches do notexist for one-off builds.\n\n\n\ncache\n\n\n\npathdir-path\n\nThe path to a directory to be cached.\n\nPaths are relative to the working directory of the task. Absolute pathsare not respected.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/cache"
                  }
                ]
              }
            }
          ]
        },
        "run": {
          "description": "The command to execute in the container.\n\nNote that this isnotprovided as a script blob, but explicit\n\n`path`and`args`values; this allows`fly`to forwardarguments to the script, and forces your config`.yml`to stay fairlysmall.\n\n\n\ncommand\n\n\n\npathfile-path\n\nThe name of or path to the executable to run.\n\n\n\n`path`is relative to the working directory. If`dir`isspecified to set the working directory, then`path`is relative toit.\n\nThis is commonly a path to a script provided by one of the task's inputs,e.g.`my-resource/scripts/test`. It could also be a command like\n\n`bash`(respecting standard`$PATH`lookup rules), or an absolutepath to a file to execute, e.g.`/bin/bash`.\n\n\n\n\n\n\n\nargs[string]\n\nArguments to pass to the command. Note that when executed with\n\nfly-cliFly, any arguments passed tofly-execute\n\nare appended to this array.\n\n\n\n\n\n\n\ndirdir-path\n\nA directory, relative to the initial working directory, to set as theworking directory when running the script.\n\n\n\n\n\n\n\nuserstring\n\nExplicitly set the user to run as. If not specified, this defaults to theuser configured by the task's image. If not specified there, it's up tothe Garden backend, and may be e.g.`root`on Linux.",
          "oneOf": [
            {
              "$ref": "#/definitions/command"
            }
          ]
        },
        "params": {
          "description": "A key-value mapping of string keys and values that are exposed to the taskvia environment variables.\n\nPipelines can override these params by setting\n\nschema.task.paramson thetask-step. This is a commonmethod of providing credentials to a task.",
          "oneOf": [
            {
              "$ref": "#/definitions/env_vars"
            }
          ]
        },
        "image_resource": {
          "description": "The container image to run with, as provided by an anonymous\n\nresourcesresourcedefinition.\n\nWhenever the task runs, the anonymous resource will be`check`ed todiscover the latest version available. The image will then be fetched ontothe worker, if necessary, just prior to running the task.\n\nTo use an image provided by a previous step within your build plan, set\n\nschema.task.imageon thetask-step\n\ninstead.\n\n\n\n\n\n\n\n**NOTE:**This field is only required for tasks targeting the\n\nschema.task-config.platformLinux platform. This field will beignored for Windows and Darwin workers. Windows containers are currentlynot supported and Darwin does not have native containers. The task willrun inside a clean temporary directory on the Windows/Darwin worker withany inputs and outputs copied into the same directory. Any dependenciesshould be pre-installed on the worker.\n\n\n\n\n\n\n\n@example Using the`golang`Docker image\n\n\nThe following task config will use the`golang`Dockerimagehttps://hub.docker.com/_/golangto run`go version`:\n\n\n\n```yaml\nplatform: linux\n\nimage_resource:\n  type: registry-image\n  source: {repository: golang}\n\nrun:\n  path: go\n  args: [version]\n```\n\n\n\n\n\n\n\n\n\nanonymous_resource\n\n\n\ntyperesource_type.name\n\nThe type of the resource. Usually`registry-image`.\n\nYou can use any resource type that returns a filesystem in the correctformat: a`/rootfs`directory containing a full filesystem, and a\n\n`metadata.json`file containing.\n\n\n\n\n\n\n\nsourceconfig\n\nThe configuration for the resource; see\n\nschema.resource.source.\n\n\n\n\n\n\n\nparamsconfig\n\nA map of arbitrary configuration to forward to the resource. Refer to theresource type's documentation to see what it supports.\n\n\n\n\n\n\n\nversionversion\n\nA specific version of the resource to fetch. This should be a map withstring keys and values. If not specified, the latest version will befetched.",
          "oneOf": [
            {
              "$ref": "#/definitions/anonymous_resource"
            }
          ]
        },
        "container_limits": {
          "description": "CPU and memory limits to enforce on the task container.\n\nNote that these values, when specified, will override any limits set bypassing the`--default-task-cpu-limit`or\n\n`--default-task-memory-limit`flags to the`concourse web`command.\n\n\n\ncontainer_limits\n\n\n\ncpunumber\n\nThe maximum amount of CPU available to the task container, measured inshares. 0 means unlimited.\n\nCPU shares are relative to the CPU shares of other containers on aworker. For example, if you have two containers both with a CPUlimit of 2 shares then each container will get 50% of the CPU's time.\n\n\n\n```\nContainer A: 2 shares - 50% CPU\nContainer B: 2 shares - 50% CPU\nTotal CPU shares declared: 4\n```\n\n\n\nIf you introduce another container then the number of CPU time percontainer changes. CPU shares are relative to each other.\n\n```\nContainer A: 2 shares - 25% CPU\nContainer B: 2 shares - 25% CPU\nContainer C: 4 shares - 50% CPU\nTotal CPU shares declared: 8\n```\n\n\n\n\n\n\n\n\n\nmemorynumber\n\nThe maximum amount of memory available to the task container, measured inbytes. 0 means unlimited.",
          "oneOf": [
            {
              "$ref": "#/definitions/container_limits"
            }
          ]
        },
        "inputs": {
          "description": "The set of artifacts used by task, determining which artifacts will beavailable in the current directory when the task runs.\n\nThese are satisfied byget-steps or\n\nschema.task-config.outputsof a previous task. These can alsobe provided by`-i`withfly-execute.\n\nIf any required inputs are missing at run-time, then the task will errorimmediately.\n\n\n\ninput\n\n\n\nnameidentifier\n\nThe name of the input.\n\n\n\n\n\n\n\npathdir-path\n\nThe path where the input will be placed. If not specified, the input's\n\n`name`is used.\n\nPaths are relative to the working directory of the task. Absolute pathsare not respected.\n\n\n\n\n\n\n\noptionalboolean\n\n\n\nDefault`false`.If`true`, then the input is notrequired by the task. The task may run even if this input is missing.\n\nAn`optional`input that is missing will not appear in the currentdirectory of the running task.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/input"
                  }
                ]
              }
            }
          ]
        },
        "platform": {
          "description": "The platform the task should run on. This determines the pool of workersthat the task can run against.\n\nTechnically any string value is allowed so long as a worker advertises thesame platform, but in practice only`linux`,`darwin`, and\n\n`windows`are in use.",
          "type": "string",
          "enum": [
            "linux",
            "darwin",
            "windows"
          ]
        },
        "outputs": {
          "description": "The artifacts produced by the task.\n\nEach output configures a directory to make available to later steps in the\n\nbuild-plansbuild plan. The directory will be automaticallycreated before the task runs, and the task should place any artifacts itwants to export in the directory.\n\n\n\noutput\n\n\n\nnameidentifier\n\nThe name of the output. The contents under`path`will be madeavailable to the rest of the plan under this name.\n\n\n\n\n\n\n\npathdir-path\n\nThe path to a directory where the output will be taken from. If notspecified, the output's`name`is used.\n\nPaths are relative to the working directory of the task. Absolute paths are not respected.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/output"
                  }
                ]
              }
            }
          ]
        }
      }
    },
    "vault_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "auth_backend": {
          "description": "Authenticate using an auth backend, e.g.`cert`or\n\n`approle`.\n\nSeevault-approle-authorvault-cert-authformore information.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "namespace": {
          "description": "AVaultnamespacehttps://www.vaultproject.io/docs/enterprise/namespaces/index.html\n\nto operate under.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "ca_cert": {
          "description": "The PEM encoded contents of a CA certificate to use whenconnecting to the API.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "auth_params": {
          "description": "A key-value map of parameters to pass during authentication.\n\nSeevault-approle-authfor more information.",
          "oneOf": [
            {
              "type": "object",
              "patternProperties": {
                ".*": {
                  "type": "string"
                }
              }
            }
          ]
        },
        "auth_max_ttl": {
          "description": "Maximum duration to elapse before forcing the client to log inagain.",
          "oneOf": [
            {
              "$ref": "#/definitions/duration"
            }
          ]
        },
        "server_name": {
          "description": "The expected name of the server when connecting through TLS.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "client_token": {
          "description": "Authenticate via a periodic client token.\n\nSeevault-periodic-tokenfor more information.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "lookup_templates": {
          "description": "Default`[\"/{{.Team}}/{{.Pipeline}}/{{.Secret}}\", \"/{{.Team}}/{{.Secret}}\"]`.\n\n\n\nA list of path templates to be expanded in a team and pipeline contextsubject to the`path_prefix`and`namespace`.\n\nSeevault-lookup-templatesfor more information.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/string"
                  }
                ]
              }
            }
          ]
        },
        "client_key": {
          "description": "A PEM encoded client key, for use with TLS based auth.\n\nSeevault-cert-authfor more information.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "auth_retry_initial": {
          "description": "When retrying during authentication, start with this retryinterval. The interval will increase exponentially until\n\n`auth_retry_max`is reached.",
          "oneOf": [
            {
              "$ref": "#/definitions/duration"
            }
          ]
        },
        "auth_retry_max": {
          "description": "When failing to authenticate, give up after this amount oftime.",
          "oneOf": [
            {
              "$ref": "#/definitions/duration"
            }
          ]
        },
        "path_prefix": {
          "description": "Default`/concourse`.A prefix under which tolook for all credential values.\n\nSeevault-path-prefixfor more information.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "url": {
          "description": "The URL of the Vault API.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "client_cert": {
          "description": "A PEM encoded client certificate, for use with TLS based auth.\n\nSeevault-cert-authfor more information.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "shared_path": {
          "description": "An additional path under which credentials will be looked up.\n\nSeevault-shared-pathfor more information.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "insecure_skip_verify": {
          "description": "Skip TLS validation. Not recommended. Don't do it. No really,don't.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        }
      }
    },
    "dummy_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "vars": {
          "description": "A mapping of var name to var value.",
          "oneOf": [
            {
              "$ref": "#/definitions/vars"
            }
          ]
        }
      }
    },
    "put_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "resource": {
          "description": "Defaults to the value of`put`.The resource to update,as configured inschema.pipeline.resources.\n\n\n\n@example Re-label Put Resource\n\n\n\n\n```yaml\njobs:\n- name: fetch-repo\n  plan:\n    # puts to \"repo\" and fetches new version under artifact name \"thecode\"\n  - put: thecode\n    resource: repo\n    params:\n      version: put-only\n  - task: ls-repo\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      # pass the \"thecode\" artifact into the task\n      inputs:\n      - name: thecode\n      run:\n        path: ls\n        args: [\"-lah\",\"thecode\"]\n\nresources:\n- name: repo\n  type: mock\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "params": {
          "description": "Arbitrary configuration to pass to the resource. Refer to the resourcetype's documentation to see what it supports.\n\n\n\n@example Putting with params\n\n\n\n\n```yaml\njobs:\n- name: resource-params\n  plan:\n  - put: cyberdeck\n    params:\n      version: \"made-via-params\"\n\nresources:\n- name: cyberdeck\n  type: mock\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/config"
            }
          ]
        },
        "get_params": {
          "description": "Arbitrary configuration to pass to the resource during the implicit\n\n`get`step. Refer to the resource type's documentation to see whatit supports.\n\n\n\n@example Parameterizing the implicit`get`\n\n\nYou can control the settings of the implicit`get`stepby setting`get_params`. For example, if you did not want a`put`\n\nstep utilizing the\n\n`registry-image`resourcetypehttps://github.com/concourse/registry-image-resourceto download theimage, you would implement your`put`step as such:\n\n\n\n```yaml\nplan:\n- put: app-image\n  params:\n    build: git-resource\n  get_params:\n    skip_download: true\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/config"
            }
          ]
        },
        "inputs": {
          "description": "Default`all`.When not set, or set to`all`, allartifacts will be provided. This can result in slow performance if theprior steps in the build plan register a bunch of large artifactsbefore this step, so you may want to consider being explicit.\n\nIf configured as a list of identifiers, only the listed artifacts willbe provided to the container.\n\nIf set to`detect`, the artifacts are detected based on theconfiguredschema.put.paramsby looking for all string valuesand using the first path segment as an identifier. (This may become thedefault in the future.)\n\n\n\n@example Put Input Methods\n\n\n\n\n```yaml\njobs:\n- name: put-input-methods\n  plan:\n  - in_parallel:\n    - get: repo-dev\n    - get: repo-master\n    - get: app-image\n    - get: ci\n  - put: all-inputs\n    resource: repo\n    inputs: all # default option\n    params:\n      file: ci/version.txt\n  - put: detect-inputs\n    resource: repo\n    inputs: detect # will only stream the \"ci\" artifact\n    params:\n      file: ci/version.txt\n  - put: explicit-inputs\n    resource: repo\n    inputs: # explicitly list artifacts to stream to put step\n      - ci\n    params:\n      file: ci/version.txt\n\nresources:\n- name: repo\n  type: mock\n- name: repo-dev\n  type: mock\n- name: repo-master\n  type: mock\n- name: app-image\n  type: mock\n- name: ci\n  type: mock\n  source:\n    create_files:\n      version.txt: \"42\"\n```",
          "oneOf": [
            {
              "type": "string",
              "enum": [
                "all"
              ]
            },
            {
              "type": "string",
              "enum": [
                "detect"
              ]
            },
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/identifier"
                  }
                ]
              }
            }
          ]
        },
        "put": {
          "description": "When the step succeeds, the version by the step will be immediatelyfetched via an additional implicitget-step. This is sothat later steps in your plan can use the artifact that was produced.The artifact will be available under the identifier`put`\n\nspecifies.\n\n\n\n@example Getting and Putting\n\n\nThe following plan fetches a version using\n\nget-step`get`and pushes it to another resourceusingput-step`put`:\n\n\n\n```yaml\njobs:\n- name: get-and-pull\n  plan:\n  - get: the-ice\n  - put: cyberdeck\n    params:\n      file: the-ice/version.txt\n\nresources:\n- name: the-ice\n  type: mock\n  source:\n    create_files:\n      version.txt: \"made-via-source\"\n- name: cyberdeck\n  type: mock\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            },
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        }
      }
    },
    "output": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "path": {
          "description": "The path to a directory where the output will be taken from. If notspecified, the output's`name`is used.\n\nPaths are relative to the working directory of the task. Absolute paths are not respected.",
          "oneOf": [
            {
              "$ref": "#/definitions/dir_path"
            }
          ]
        },
        "name": {
          "description": "The name of the output. The contents under`path`will be madeavailable to the rest of the plan under this name.",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        }
      }
    },
    "display_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "background_image": {
          "description": "Allow users to specify a custom background image which is put at 30%opacity, grayscaled and blended into existing background. Must be anhttp, https, or relative URL.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        }
      }
    },
    "step": {
      "type": "string"
    },
    "vault_var_source": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "config": {
          "description": "Configuration for the Vault server has the following schema:\n\n\n\nvault_config\n\n\n\nurlstring\n\nThe URL of the Vault API.\n\n\n\n\n\n\n\nca_certstring\n\nThe PEM encoded contents of a CA certificate to use whenconnecting to the API.\n\n\n\n\n\n\n\npath_prefixstring\n\n\n\nDefault`/concourse`.A prefix under which tolook for all credential values.\n\nSeevault-path-prefixfor more information.\n\n\n\n\n\n\n\nlookup_templates[string]\n\n\n\nDefault`[\"/{{.Team}}/{{.Pipeline}}/{{.Secret}}\", \"/{{.Team}}/{{.Secret}}\"]`.\n\n\n\nA list of path templates to be expanded in a team and pipeline contextsubject to the`path_prefix`and`namespace`.\n\nSeevault-lookup-templatesfor more information.\n\n\n\n\n\n\n\nshared_pathstring\n\nAn additional path under which credentials will be looked up.\n\nSeevault-shared-pathfor more information.\n\n\n\n\n\n\n\nnamespacestring\n\nAVaultnamespacehttps://www.vaultproject.io/docs/enterprise/namespaces/index.html\n\nto operate under.\n\n\n\n\n\n\n\nclient_certstring\n\nA PEM encoded client certificate, for use with TLS based auth.\n\nSeevault-cert-authfor more information.\n\n\n\n\n\n\n\nclient_keystring\n\nA PEM encoded client key, for use with TLS based auth.\n\nSeevault-cert-authfor more information.\n\n\n\n\n\n\n\nserver_namestring\n\nThe expected name of the server when connecting through TLS.\n\n\n\n\n\n\n\ninsecure_skip_verifyboolean\n\nSkip TLS validation. Not recommended. Don't do it. No really,don't.\n\n\n\n\n\n\n\nclient_tokenstring\n\nAuthenticate via a periodic client token.\n\nSeevault-periodic-tokenfor more information.\n\n\n\n\n\n\n\nauth_backendstring\n\nAuthenticate using an auth backend, e.g.`cert`or\n\n`approle`.\n\nSeevault-approle-authorvault-cert-authformore information.\n\n\n\n\n\n\n\nauth_params{string: string}\n\nA key-value map of parameters to pass during authentication.\n\nSeevault-approle-authfor more information.\n\n\n\n\n\n\n\nauth_max_ttlduration\n\nMaximum duration to elapse before forcing the client to log inagain.\n\n\n\n\n\n\n\nauth_retry_maxduration\n\nWhen failing to authenticate, give up after this amount oftime.\n\n\n\n\n\n\n\nauth_retry_initialduration\n\nWhen retrying during authentication, start with this retryinterval. The interval will increase exponentially until\n\n`auth_retry_max`is reached.",
          "oneOf": [
            {
              "$ref": "#/definitions/vault_config"
            }
          ]
        },
        "type": {
          "description": "The`vault`type supports configuring a\n\nVaulthttps://www.vaultproject.ioserver as a\n\n`((var))`source.",
          "type": "string",
          "enum": [
            "vault"
          ]
        }
      }
    },
    "dir_path": {
      "type": "string"
    },
    "dummy_var_source": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "config": {
          "description": "dummy_config\n\n\n\nvarsvars\n\nA mapping of var name to var value.",
          "oneOf": [
            {
              "$ref": "#/definitions/dummy_config"
            }
          ]
        },
        "type": {
          "description": "The`dummy`type supports configuring a static map of vars to values.\n\nThis is really only useful if you have no better alternative for credentialmanagement but still have sensitive values that you would like to\n\ncreds-redactingredactthem from build output.",
          "type": "string",
          "enum": [
            "dummy"
          ]
        }
      }
    },
    "config": {
      "type": "object",
      "patternProperties": {
        ".*": {
          "additionalProperties": true
        }
      }
    },
    "in_parallel_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "fail_fast": {
          "description": "Default`false`.When enabled the parallel step willfail fast by returning as soon as any sub-step fails. This means that running stepswill be interrupted and pending steps will no longer be scheduled.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "limit": {
          "description": "Default unlimited.A sempahore which limits theparallelism when executing the steps in a`in_parallel`step.When set, the number of running steps will not exceed the limit.\n\nWhen not specified,`in_parallel`will execute all stepsimmediately.\n\n@example Limiting parallelism\n\n\nUsing`limit`is useful for performing parallel execution of agrowing number of tasks without overloading your workers. In theexample below, two tasks will be run in parallel and in order untilall steps have been executed:\n\n\n\n```yaml\njobs:\n- name: limit-in-parallel\n  plan:\n  - get: examples\n  - in_parallel:\n      limit: 2\n      steps:\n      - task: print-date\n        file: examples/tasks/print-date.yml\n      - task: hello-world\n        file: examples/tasks/hello-world.yml\n      - task: print-var\n        file: examples/tasks/print-var.yml\n        vars:\n          my-var: hello\n          second-var: good-bye\n\n\nresources:\n- name: examples\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/number"
            }
          ]
        },
        "steps": {
          "description": "The steps to perform in parallel.\n\n@example Fetching artifacts in parallel\n\n\nUsing the`in_parallel`step where possible is the easiest wayto speeding up a builds.\n\nIt is often used to fetch all dependent resources together at thestart of a build plan:\n\n\n\n```yaml\njobs:\n- name: get-in-parallel\n  plan:\n  - in_parallel:\n      limit: 2\n      fail_fast: false\n      steps:\n      - get: ci\n      - get: repo\n      - get: code\n\n\nresources:\n- name: repo\n  type: mock\n- name: code\n  type: mock\n- name: ci\n  type: mock\n```",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/step"
                  }
                ]
              }
            }
          ]
        }
      }
    },
    "string": {
      "type": "string"
    },
    "number": {
      "type": "number"
    },
    "vars": {
      "type": "string"
    },
    "group_config": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "name": {
          "description": "A unique name for the group. This should be short and simple as it willbe used as the tab name for navigation.",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "jobs": {
          "description": "A list of jobs that should appear in this group. A job mayappear in multiple groups. Neighbours of jobs in the current group will alsoappear on the same page in order to give context of the location of thegroup in the pipeline.\n\nYou may also use any validglobhttps://www.man7.org/linux/man-pages/man7/glob.7.html\n\nto represent several jobs, e.g.:\n\n\n\n```yaml\ngroups:\n- name: develop\n  jobs:\n  - terraform-*\n  - test\n  - deploy-{dev,staging}\n- name: ship\n  jobs:\n  - deploy-prod\n- name: all\n  jobs:\n  - \"*\"\n```\n\n\n\nIn this example, the`develop`group will match\n\n`terraform-apply`,`terraform-destroy`,`test`,\n\n`deploy-dev`,`deploy-staging`. The`ship`group will only match\n\n`deploy-prod`. The`all`group will match all jobs in the pipeline.\n\n\n\nNote that depending on how it's used,`*`,`{`, and\n\n`}`have special meaning in YAML, and may need to be quoted (aswas done in the`all`job above)",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/string"
                  }
                ]
              }
            }
          ]
        }
      }
    },
    "try_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "try": {
          "description": "Performs the given step, ignoring any failure and masking it withsuccess.\n\nThis can be used when you want to perform some side-effect, but youdon't really want the whole build to fail if it doesn't work.\n\n\n\n@example Allowing non-critical behavior to fail\n\n\nWhen emitting logs somewhere for analyzing later, if the destination flakesout it may not really be critical, so we may want to just swallow theerror:\n\n\n\n```yaml\nplan:\n- task: run-tests\n  config: # ...\n  on_success:\n    try:\n      put: test-logs\n      params:\n        from: run-tests/*.log\n- task: do-something-else\n  config: # ...\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/step"
            }
          ]
        }
      }
    },
    "cache": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "path": {
          "description": "The path to a directory to be cached.\n\nPaths are relative to the working directory of the task. Absolute pathsare not respected.",
          "oneOf": [
            {
              "$ref": "#/definitions/dir_path"
            }
          ]
        }
      }
    },
    "env_vars": {
      "type": "string"
    },
    "identifier": {
      "type": "string"
    },
    "version": {
      "type": "string"
    },
    "resource_type": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "defaults": {
          "description": "The default configuration for the resource type. This variesby resource type, and is a black box to Concourse; it is merged with(duplicate fields are overwritten by)schema.resource.source\n\nand passed to the resource at runtime.\n\n\n\n@example Setting default configuration for resources\n\n\n\n\n```yaml\nresource_types:\n- name: gcs\n  type: registry-image\n  source:\n    repository: frodenas/gcs-resource\n  defaults:\n    json_key: ((default_key))\n\nresources:\n- name: bucket-a\n  type: gcs\n  source:\n    bucket: a\n\n- name: bucket-b\n  type: gcs\n  source:\n    bucket: b\n\n- name: bucket-c\n  type: gcs\n  source:\n    bucket: c\n    json_key: ((different_key))\n```\n\n\n\n\n\n\n\n\n\n@example Overriding default resource types\n\n\nSince it's possible to overwrite the base resource types, it can beused to give defaults to resources at the pipeline level.\n\n\n\n```yaml\nresource_types:\n- name: registry-image\n  type: registry-image\n  source:\n    repository: concourse/registry-image-resource\n  defaults:\n    registry_mirror:\n      host: https://registry.mirror.example.com\n\nresources:\n- name: mirrored-image\n  type: registry-image\n  source:\n    repository: busybox\n```\n\n\n\nAlternatively, the web node can be configured to use\n\nresource-defaultsdefaults for base resource types",
          "oneOf": [
            {
              "$ref": "#/definitions/config"
            }
          ]
        },
        "source": {
          "description": "The configuration for the resource type's resource. This variesby resource type, and is a black box to Concourse; it is blindly passed tothe resource at runtime.\n\nTo use`registry-image`as an example, the source would contain somethinglike`repository: username/reponame`. See theRegistry Imageresourcehttps://github.com/concourse/registry-image-resource(or whateverresource type your resource type uses) for more information.",
          "oneOf": [
            {
              "$ref": "#/definitions/config"
            }
          ]
        },
        "privileged": {
          "description": "Default`false`.If set to`true`, the resource'scontainers will be run with full capabilities, as determined by the workerbackend the task runs on.\n\nFor Linux-based backends it typically determines whether or not thecontainer will run in a separate user namespace, and whether the\n\n`root`user is \"actual\"`root`(if set to`true`) or a usernamespaced`root`(if set to`false`, the default).\n\nThis is a gaping security hole; only configure it if the resource type needsit (which should be called out in its documentation). This is not up to theresource type to decide dynamically, so as to prevent privilege escalationvia third-party resource type exploits.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "params": {
          "description": "Arbitrary config to pass when running the`get`to fetch the resourcetype's image.",
          "oneOf": [
            {
              "$ref": "#/definitions/config"
            }
          ]
        },
        "tags": {
          "description": "Default`[]`.A list of tags to determine which workers thechecks will be performed on. You'll want to specify this if the source isinternal to a worker's network, for example. See also\n\nschema.tags.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/string"
                  }
                ]
              }
            }
          ]
        },
        "check_every": {
          "description": "Default`1m`.The interval on which to check for new versionsof the resource type. Acceptable interval options are defined by the\n\ntime.ParseDurationfunctionhttps://golang.org/pkg/time/#ParseDuration.",
          "oneOf": [
            {
              "$ref": "#/definitions/duration"
            }
          ]
        },
        "name": {
          "description": "The name of the resource type. This should be short and simple. This namewill be referenced byschema.pipeline.resourcesdefined withinthe same pipeline, andschema.task-config.image_resources usedby tasks running in the pipeline.\n\nPipeline-provided resource types can override the core resource types byspecifying the same name.",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "type": {
          "description": "The type of the resource used to provide the resource type's containerimage.\n\nThis is a bit meta. Usually this value will be`registry-image`as theresource type must result in a container image.\n\nA resource type's type can refer to other resource types, and can also use thecore type that it's overriding. This is useful for bringing in a newer orforked`registry-image`resource.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            },
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        }
      }
    },
    "container_limits": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "cpu": {
          "description": "The maximum amount of CPU available to the task container, measured inshares. 0 means unlimited.\n\nCPU shares are relative to the CPU shares of other containers on aworker. For example, if you have two containers both with a CPUlimit of 2 shares then each container will get 50% of the CPU's time.\n\n\n\n```\nContainer A: 2 shares - 50% CPU\nContainer B: 2 shares - 50% CPU\nTotal CPU shares declared: 4\n```\n\n\n\nIf you introduce another container then the number of CPU time percontainer changes. CPU shares are relative to each other.\n\n```\nContainer A: 2 shares - 25% CPU\nContainer B: 2 shares - 25% CPU\nContainer C: 4 shares - 50% CPU\nTotal CPU shares declared: 8\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/number"
            }
          ]
        },
        "memory": {
          "description": "The maximum amount of memory available to the task container, measured inbytes. 0 means unlimited.",
          "oneOf": [
            {
              "$ref": "#/definitions/number"
            }
          ]
        }
      }
    },
    "resource": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "source": {
          "description": "The configuration for the resource. This varies by resource type, and is a blackbox to Concourse; it is blindly passed to the resource at runtime.\n\nTo use`git`as an example, the source may contain the repo URI, thebranch of the repo to track, and a private key to use when pushing/pulling.\n\nBy convention, documentation for each resource type's configuration isin each implementation's`README`.\n\nYou can find the source for the resource types provided with Concourse at the\n\nConcourse GitHuborganizationhttps://github.com/concourse?q=-resource.",
          "oneOf": [
            {
              "$ref": "#/definitions/config"
            }
          ]
        },
        "check_timeout": {
          "description": "Default`1h`.The time limit on checking new versions ofresources. Acceptable interval options are defined by the\n\ntime.ParseDurationfunctionhttps://golang.org/pkg/time/#ParseDuration.",
          "oneOf": [
            {
              "$ref": "#/definitions/duration"
            }
          ]
        },
        "check_every": {
          "description": "Default`1m`.The interval on which to check for new versionsof the resource. Acceptable interval options are defined by the\n\ntime.ParseDurationfunctionhttps://golang.org/pkg/time/#ParseDuration.\n\nIf set to`never`the resource will not be automatically checked. Theresource can still be checked manually via the web UI, fly, or webhooks.",
          "oneOf": [
            {
              "$ref": "#/definitions/duration"
            },
            {
              "type": "string",
              "enum": [
                "never"
              ]
            }
          ]
        },
        "version": {
          "description": "A version to pin the resource to across the pipeline. This has the sameeffect as settingschema.get.versionon every\n\nget-stepreferencing the resource.\n\nResources can also be temporarily pinned to a version via the API and web UI.However this functionality is disabled if the resource is pinned viaconfiguration, and if a pipeline is configured to have a version pinned whilealso pinned in the web UI, the configuration takes precedence and will clearout the temporary pin.",
          "oneOf": [
            {
              "$ref": "#/definitions/version"
            }
          ]
        },
        "expose_build_created_by": {
          "description": "Default`false`.If set to`true`, environment variable\n\nresource-metadata`BUILD_CREATED_BY`will be availablein the metadata of aget-stepget stepor\n\nput-stepput step.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "old_name": {
          "description": "The old name of the resource. If configured, the history of the old resource will beinherited to the new one. Once the pipeline is set, this field can beremoved as the history has been transferred.\n\n\n\n@example Renaming a resource\n\n\nThis can be used to rename a resource without losing its history, like so:\n\n\n\n```yaml\nresources:\n- name: new-name\n  old_name: current-name\n  type: git\n  source: {uri: \"https://github.com/vito/booklit\"}\n```\n\n\n\nAfter the pipeline is set, the resource was successfully renamed, so the `old_name` field canbe removed from the resource:\n\n\n\n```yaml\nresources:\n- name: new-name\n  type: git\n  source: {uri: \"https://github.com/vito/booklit\"}\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "icon": {
          "description": "The name of aMaterial Design iconhttps://materialdesignicons.com/\n\nto show next to the resource name in the web UI. For example,\n\n`github`.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "name": {
          "description": "The name of the resource. This should be short and simple. This name willbe referenced bybuild-plansbuild plansof jobs in thepipeline.",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "public": {
          "description": "Default`false`.If set to`true`, the metadata for eachversion of the resource will be viewable by unauthenticated users (assumingthe pipeline has beenexposingexposed).\n\nResource metadata should never contain credentials or secret information, butthis is off by default just to be safe in case users don't want to showthings like commit messages and authors to the public.\n\nNote: even when set to`false`, the versions identifiers will bevisible. In addition, if a resource is fetched in a build whose job is marked\n\nschema.job.public, metadata will be visible in the build output.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        },
        "tags": {
          "description": "Default`[]`.A list of tags to determine which workers thechecks will be performed on. You'll want to specify this if the source isinternal to a worker's network, for example.\n\n\n\n\n\nThis does not apply tags to allget-stepget stepsor\n\nput-stepput stepsthat use the resource. If you want these stepsto use tags, you must setschema.tagsfor each step.",
          "oneOf": [
            {
              "type": "array",
              "items": {
                "oneOf": [
                  {
                    "$ref": "#/definitions/string"
                  }
                ]
              }
            }
          ]
        },
        "type": {
          "description": "Theresource-typesresource typeimplementing the resource.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        },
        "webhook_token": {
          "description": "If specified, web hooks can be sent to trigger an immediatecheck\n\nof the resource, specifying this value as a primitive form ofauthentication via query params.\n\nAfter configuring this value, you would then configure your hook sender withthe following painfully long path appended to your external URL:\n\n\n\n`\n      /api/v1/teams/TEAM_NAME/pipelines/PIPELINE_NAME/resources/RESOURCE_NAME/check/webhook?webhook_token=WEBHOOK_TOKEN\n    `\n\n\n\nFormanaging-instanced-pipelinesinstance pipelinesyou willneed to include the pipeline vars for a single pipeline instance. Currentlyyou can not have webhooks for all instances of a pipeline.\n\nThe pipeline vars should be added to the webhook URL asURLparametershttps://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_is_a_URL#parameters\n\nwith the format`vars.MY-VAR=\"SOME-VALUE\"`. A webhook URL for apipeline instance may look like this:\n\n\n\n`\n      /api/v1/teams/TEAM_NAME/pipelines/PIPELINE_NAME/resources/RESOURCE_NAME/check/webhook?webhook_token=WEBHOOK_TOKEN&vars.my-var=\"some-value\"&vars.second-var=\"two\"\n    `\n\n\n\nNote that the request payload sent to this API endpoint is entirelyignored.  You should configure the resource as if you're not using webhooks, as the resourceschema.resource.sourceconfigis stillthe \"source of truth.\"",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        }
      }
    },
    "task_step": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "task": {
          "description": "The identifier value is just a name - short and sweet. The value isshown in the web UI but otherwise has no affect on anything. This maychange in the future;RFC#32https://github.com/concourse/rfcs/pull/32proposes that the namebe used to reference a file within the project.\n\n\n\n@example Functions from inputs to outputs\n\n\nYou can think of tasks like functions. They have predefined inputsand outputs and can be written in idempotent ways.\n\nThe following pipeline contains a function that increments a number.You can think of the task`add-one`like this pseudo-function:\n\n\n\n```\nfunc AddOne(num int) int {\n  return num + 1\n}\n```\n\n\n\n\n\n```yaml\njobs:\n- name: idempotent-task\n  plan:\n  - get: counter\n  - task: add-one\n    config:\n      platform: linux\n      image_resource:\n        type: mock\n        source: {mirror_self: true}\n      inputs:\n      - name: counter\n      outputs:\n      - name: counter\n      run:\n        path: sh\n        args:\n        - -c\n        - |\n          COUNTER=$(cat counter/version)\n          NEXT=$(($COUNTER + 1))\n          echo \"new version: $NEXT\"\n          echo $NEXT > counter/next\n  - put: counter\n    params:\n      file: counter/next\n\nresources:\n- name: counter\n  type: mock\n  source:\n    initial_version: \"1\"\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "file": {
          "description": "A dynamic alternative toschema.task.config.\n\n\n\n`file`points at a`.yml`file containing the\n\ntaskstask config, which allows this to be tracked withyour resources.\n\nThe first segment in the path should refer to another source from theplan, and the rest of the path is relative to that source.\n\nThe content of the config file may contain template`((vars))`,which will be filled in usingschema.task.vars\n\nor a configuredcredscredential manager.\n\n@example Using a task config file\n\n\nUsesthis config filehttps://github.com/concourse/examples/blob/master/tasks/hello-world.yml.\n\n```yaml\njobs:\n- name: task-config-in-file\n  plan:\n  - get: ci\n  - task: config-from-file\n    file: ci/tasks/hello-world.yml\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/file_path"
            }
          ]
        },
        "image": {
          "description": "Specifies an artifact source containing an image to use for the task.This overrides anyschema.task-config.image_resourceconfiguration present inthe task configuration.\n\nThis is very useful when part of your pipeline involves building an image,possibly with dependencies pre-baked. You can then propagate that imagethrough the rest of your pipeline, guaranteeing that the correct version (andthus a consistent set of dependencies) is used throughout your pipeline.\n\n\n\n@example Fetching and using an image\n\n\nThis can be used to explicitly keep track of dependent images. Youcould also modify it to build and push the image in one job and useit in later jobs. Seebuilding-and-pushing-an-image.\n\n\n\n```yaml\nresources:\n- name: golang\n  type: registry-image\n  source:\n    repository: golang  # could also be the full URL \"docker.io/golang\"\n    tag: \"1.17\"\n\njobs:\n- name: fetch-and-run-image\n  plan:\n  - get: golang\n  - task: use-fetched-image-in-task\n    image: golang   # reference the image from the get step\n    config:\n      platform: linux\n      run:\n        path: go\n        args: [\"version\"]\n```\n\n\n\n\n\n\n\n\n\n@example Building and using an image\n\n\n\n\nbuilding-an-image-and-using-it-in-a-task",
          "oneOf": [
            {
              "$ref": "#/definitions/identifier"
            }
          ]
        },
        "vars": {
          "description": "A map of template variables to pass to an external task. Not to beconfused withschema.task.params, which provides\n\nenvironment variablesto the task.\n\nThis is to be used with external tasks defined in\n\nschema.task.file.\n\n\n\n@example Parameterizing a task config file with vars\n\n\nA var may be statically passed like so:\n\n\n\n```yaml\njobs:\n- name: task-vars\n  plan:\n  - get: ci\n  - task: override-task-vars\n    file: ci/tasks/print-var.yml\n    vars: # statically defined vars\n      my-var: \"Cookies are the best\"\n      second-var: \"chips are a close second\"\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```\n\n\n\nWhen run with the followingtaskstask config:\n\n\n\nyamlhttps://raw.githubusercontent.com/concourse/examples/master/tasks/print-var.yml\n\n\n\nThe`\"((my-var))\"`will be resolved to`\"Cookies are the\n          best\"`and`((second-var))`will be resolved to`\"chips are\n          a close second\"`.\n\nThis can also be used in combination withvarsfrom a\n\ncredscredential manager(i.e. Vault) as a way to re-mapvariable names to match what the task is expecting:\n\n\n\n```yaml\njobs:\n- name: task-vars\n  plan:\n  - get: ci\n  - task: override-task-vars\n    file: ci/tasks/print-var.yml\n    vars: # re-mapped vars\n      my-var: ((var-from-vault))\n      second-var: ((apple.type))\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/vars"
            }
          ]
        },
        "output_mapping": {
          "description": "A map from task output names to concrete names to register in the buildplan. This allows a task with generic output names to be used multipletimes in the same plan.\n\n\n\n@example Using with`input_mapping`\n\n\nThis is often used together with\n\nschema.task.input_mapping:\n\nGiven this task config:\n\nyamlhttps://raw.githubusercontent.com/concourse/examples/master/tasks/generic-outputs.yml\n\n\n\nThis pipeline will map the inputs and outputs of the task to matchthe name of the resources in the pipeline.\n\n```yaml\njobs:\n- name: task-output-mapping\n  plan:\n  - in_parallel:\n    - get: repo\n    - get: repo-dev\n    - get: ci\n  - task: create-outputs\n    input_mapping:\n      main: repo\n      dev: repo-dev\n    output_mapping:\n      main: repo\n      dev: repo-dev\n    file: ci/tasks/generic-outputs.yml\n  - in_parallel:\n    - put: repo\n      params:\n        file: repo/version\n    - put: repo-dev\n      params:\n        file: repo-dev/version\n\nresources:\n- name: repo\n  type: mock\n- name: repo-dev\n  type: mock\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "type": "object",
              "patternProperties": {
                ".*": {
                  "type": "string"
                }
              }
            }
          ]
        },
        "input_mapping": {
          "description": "A map from task input names to concrete names in the build plan. Thisallows a task with generic input names to be used multiple times in thesame plan, mapping its inputs to specific resources within the plan.\n\n\n\n@example Generic task input names\n\n\nThe following example demonstrates a task with generic`main`\n\nand`dev`inputs being mapped to more specific artifact names,\n\n`repo`and`repo-dev`:\n\n\n\n```yaml\njobs:\n- name: task-input-mapping\n  plan:\n  - in_parallel:\n    - get: repo\n    - get: repo-dev\n    - get: ci\n  - task: list-inputs\n    input_mapping:\n      main: repo\n      dev: repo-dev\n    file: ci/tasks/generic-inputs.yml\n\nresources:\n- name: repo\n  type: mock\n- name: repo-dev\n  type: mock\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "type": "object",
              "patternProperties": {
                ".*": {
                  "type": "string"
                }
              }
            }
          ]
        },
        "container_limits": {
          "description": "CPU and memory limits to enforce on the task container.\n\nNote that these values, when specified, will override any limits set bypassing the`--default-task-cpu-limit`or\n\n`--default-task-memory-limit`flags to the`concourse web`command.\n\nThese values will also override any configuration set on a\n\nschema.task-config.container_limitstask's config\n\n`container_limits`.\n\n\n\ncpunumber\n\nThe maximum amount of CPU available to the task container, measured inshares. 0 means unlimited.\n\nCPU shares are relative to the CPU shares of other containers on aworker. For example, if you have two containers both with a CPUlimit of 2 shares then each container will get 50% of the CPU's time.\n\n\n\n```\nContainer A: 2 shares - 50% CPU\nContainer B: 2 shares - 50% CPU\nTotal CPU shares declared: 4\n```\n\n\n\nIf you introduce another container then the number of CPU time percontainer changes. CPU shares are relative to each other.\n\n```\nContainer A: 2 shares - 25% CPU\nContainer B: 2 shares - 25% CPU\nContainer C: 4 shares - 50% CPU\nTotal CPU shares declared: 8\n```\n\n\n\n\n\n\n\n\n\nmemorynumber\n\nThe maximum amount of memory available to the task container, measured inbytes. 0 means unlimited.\n\n\n\n\n\n\n\n@example Setting CPU and Memory limits\n\n\nThis task will only be given 10MB of memory and 2 CPU shares.\n\n\n\n```yaml\njobs:\n- name: limited-resources\n  plan:\n  - task: constrained-task\n    container_limits:\n      cpu: 2 # CPU shares are relative\n      memory: 10000000 # 10MB\n    config:\n      platform: linux\n      image_resource:\n        type: registry-image\n        source: { repository: busybox }\n      run:\n        path: echo\n        args: [\"Hello world!\"]\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/container_limits"
            }
          ]
        },
        "config": {
          "description": "Thetaskstask configto execute.\n\n@example Task config\n\n\n\n\n```yaml\njobs:\n- name: job\n  public: true\n  plan:\n  - task: simple-task\n    config: # contains all field in a task config\n      platform: linux\n      image_resource:\n        type: registry-image\n        source: { repository: busybox }\n      run:\n        path: echo\n        args: [\"Hello world!\"]\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/task_config"
            }
          ]
        },
        "params": {
          "description": "A map of task environment variable parameters to set, overriding thoseconfigured in the task's`config`or`file`.\n\nThe difference betweenschema.task.params`params`\n\nandschema.task.vars`vars`is that\n\nschema.task.vars`vars`allows you to interpolate anytemplate variable in an external task file, while\n\nschema.task.params`params`can be used to overwritetask parameters specifically. Also,\n\nschema.task.params`params`can have default valuesdeclared in the task.\n\n\n\n@example Running a task with env var params\n\n\nLet's say we have aschema.task-configtask configlikeso:\n\n\n\nyamlhttps://raw.githubusercontent.com/concourse/examples/master/tasks/print-param.yml\n\n\n\nThis indicates that there are two params which can be set:\n\n`ECHO_ME`, which has a default, and`ALSO_ME`which has nodefault set.\n\nA pipeline could run the task with values passed in like so:\n\n\n\n```yaml\njobs:\n- name: task-params\n  plan:\n  - get: ci\n  - task: constrained-task\n    file: ci/tasks/print-param.yml\n    params:\n      ECHO_ME: \"Eat your fruits\"\n      ALSO_ME: \"veggies\"\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```\n\n\n\n\n\n\n\n\n\n@example Using with`((vars))`\n\n\n\n\n```yaml\njobs:\n- name: task-params\n  plan:\n  - get: ci\n  - task: constrained-task\n    file: ci/tasks/print-param.yml\n    params:\n      ECHO_ME: ((some-var))\n      ALSO_ME: ((another-var))\n\nresources:\n- name: ci\n  type: git\n  source:\n    uri: https://github.com/concourse/examples.git\n```",
          "oneOf": [
            {
              "$ref": "#/definitions/env_vars"
            }
          ]
        },
        "privileged": {
          "description": "Default`false`.If set to`true`, the task will runwith escalated capabilities available on the task's platform.\n\n\n\n\n\nSetting`privileged: true`is a gaping security hole; use wiselyand only if necessary. This is not part of the task configuration inorder to prevent privilege escalation via pull requests changing thetask file.\n\n\n\n\n\nFor the`linux`platform, this determines whether or not thecontainer will run in a separate user namespace. When set to\n\n`true`, the container's`root`user isactual\n\n\n\n`root`, i.e. not in a user namespace. This is not recommended, andshouldneverbe used with code you do not trust - e.g. pullrequests.\n\nFor macOS and Windows this field has no effect since workloads onthose machines are not containerized.",
          "oneOf": [
            {
              "$ref": "#/definitions/boolean"
            }
          ]
        }
      }
    },
    "var_source": {
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "name": {
          "description": "The name of the`((var))`source. This should be short andsimple. This name will be referencedvar-syntaxthroughoutthe config.",
          "oneOf": [
            {
              "$ref": "#/definitions/string"
            }
          ]
        }
      }
    }
  }
}
